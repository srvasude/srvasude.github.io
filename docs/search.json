[
  {
    "objectID": "posts/games_as_graphs_i/games_as_graphs_i.html",
    "href": "posts/games_as_graphs_i/games_as_graphs_i.html",
    "title": "Games As Graphs I: Bridges of Shangri-La",
    "section": "",
    "text": "This is a series on understanding various boardgames via graph representations, with this post focusing on the Bridges of Shangri-La by Leo Colovini1.\nI’ve wanted to look at some games and write down mathematical descriptions for them. For me, this is a way to understand their design better, and also be a way to generate new ideas.\nSince this is the first of several posts, I’ll describe some fundamentals of Graph Theory."
  },
  {
    "objectID": "posts/games_as_graphs_i/games_as_graphs_i.html#graph-theory-primer",
    "href": "posts/games_as_graphs_i/games_as_graphs_i.html#graph-theory-primer",
    "title": "Games As Graphs I: Bridges of Shangri-La",
    "section": "Graph Theory Primer",
    "text": "Graph Theory Primer\nA graph \\(G\\) is a set of vertices \\(V\\) and a set of edges \\(E \\subset V \\times V\\). We can draw these graphs pretty easily Figure 1 .23\n2 To differentiate the undirected and directed graph, we’d have to distinguish between ordered and unordered tuples, but I’m being intentionally not rigorous since the meaning is clear with pictures.3 Note that a graph drawing is unique. We can move the edges and vertices around.\n\n\n\n\n\n\n\n\nFigure 1: Graphs on 4 vertices\n\n\n\n\nA graph where for all edges \\((u, v) \\in E, u \\ne v\\) is called a simple graph (edges with the same start and end points are called loops).\nGraphs can come in an undirected or directed flavor. In a directed graphs, the edges have an orientation (Figure 1).\nEdges and vertices may also have weights associated with them. These are typically used to assign costs. In general, different attributes can be assigned to an edge or vertex such as color (Figure 2).\n\n\n\n\n\n\n\n\n\nFigure 2: A more complicated graph on 10 vertices. Vertices are scaled by their edge weight \\(w\\) and are colored one of two colors.\n\n\n\n\nWhat does a graph represent? As much as limited by the imagination:\n\nThe vertices \\(V\\) could represent locations, and edges \\(E\\) represent whether two locations are reachable from each other. This includes maps, road networks, but even things like chess positions for something like a Knight’s Tour.\nThe vertices \\(V\\) are individuals, and the edges \\(E\\) represent contact. This could be used for something like a social network, but also disease modelling.\nFor a directed graph \\(G\\) The vertices \\(V\\) are tasks, and the edges \\(E\\) represent which task has to be done before the next. This includes things like supply chain management.\n\nAfter representing something as a graph, there are a variety of algorithms to deduce things about the graph. Some common problems include finding the shortest path, determining if there is a cycle, graph coloring, etc.\nWe won’t be needing these but may encounter these in future discussions."
  },
  {
    "objectID": "posts/games_as_graphs_i/games_as_graphs_i.html#bridges-of-shangri-la",
    "href": "posts/games_as_graphs_i/games_as_graphs_i.html#bridges-of-shangri-la",
    "title": "Games As Graphs I: Bridges of Shangri-La",
    "section": "Bridges of Shangri-La",
    "text": "Bridges of Shangri-La\nBridges of Shangri-La is a game by Leo Colovini for 3-4 players. It takes place on a map representing monasteries in Tibet.\nYour goal is to have the most number of masters out on the board after all the bridges have collapsed. Each master is worth 1 point.\nBefore I give a rough summary of the rules, I’ll depict the board as a map for simplicity of discussion 4.\n4 This is the 4P map. The top right corner is excluded for the 3P game.\n\n\n\n\n\n\n\nFigure 3: Bridges of Shangri-La map as a graph.\n\n\n\n\n\nEach vertex represents a village, and each edge represents a bridge. Each village also has 7 spots for the 7 different types of masters 5.\n5 \n\n\nExample of placing masters\n\n\nAt the very beginning of the game, each player will place one of each type of master (in their player color) into villages of their choice. That will be 7 placements for each player. Each spot is exclusive.\nOn a players’ turn they have one of three actions:\n\nPlace a master: You can only do this in a village where you have a master of your color and if there is an unoccupied space.\nRecruit students: You can place up to 2 students. You place a master tile on a master you already have, with the top tile called a student. Each master can only have one student.\nThe Journey of the Students: Choose two connected villages, and one of them being the one travelled from (“attacker”) and the other the (“defender”). The village that has the most tiles is considered stronger (with the village with the most masters and then “defender” breaking ties).\n\nIf the “attacker” is stronger, than all students in the “attacking” village move over to the “defender”, occupying their corresponding space (removing opponents tiles if they are occupied).\nIf the “defender” is stronger, than students only move over to empty spots, and otherwise get discarded.\nAfterwards, the bridge between the two villages gets destroyed.\n\n\nOnce all bridges are destroyed the game ends, with the player with the most masters on the board winning.\n\nGraph Representation\nAs seen in Figure 3, we can represent the game board as a graph. I’ll look at a simplified version of the game where there are only two types of masters (so that there are two slots in each village). For each type of master, we can have a copy of the graph as in Figure 4.\nTo show the placement of a master, color the node the player color and set the weight to 1. Increasing the weight of a vertex to 2 will represent showing that there is a student.\n\n\n\n\n\n\n\n\nFigure 4: In our simplified version we have two types of masters. Player placements of these masters is depicted by two separate graphs, one for each type of master.\n\n\n\n\n\nFor the actions have:\n\nPlace a master: Choose one of graph copies, and then choose a vertex with weight \\(0\\), such that the same vertex already has a master of the player’s color in a different graph. Then color it your player color and change it’s weight to 1 (as seen in Figure 5 (a))\nRecruit students: Choose two vertices that have your color and are weight \\(1\\) among the copies. Then increment their weight to \\(2\\) (as seen in Figure 5 (b))\nThe Journey of the Students: Essentially following the previous rules, with vertices of weight \\(2\\) interacting and representing the movement of the students. To get the strength of a village, sum the weights of the nodes in all copies of that vertex (the effect is seen in Figure 5 (c)).\n\n\n\n\n\n\n\n\n\n\n\n\n(a) Orange placing a master of the first type.\n\n\n\n\n\n\n\n\n\n\n\n(b) Blue adding a student to each of their masters.\n\n\n\n\n\n\n\n\n\n\n\n(c) Any player initiating a journey of students.\n\n\n\n\n\n\nFigure 5: Showing Bridges of Shangri-La actions in graph form."
  },
  {
    "objectID": "posts/games_as_graphs_i/games_as_graphs_i.html#game-analysis",
    "href": "posts/games_as_graphs_i/games_as_graphs_i.html#game-analysis",
    "title": "Games As Graphs I: Bridges of Shangri-La",
    "section": "Game Analysis",
    "text": "Game Analysis\nFirst for the map, we have each vertex has at most 4 edges. That is the degree of a vertex is atmost 4, and in fact \\(3 \\le deg(v) \\le 4,\\,  \\forall v \\in V\\).\n\nThe fact the number of edges varies a little bit breaks some symmetry, with the right / top-right of the board having smaller degree vertices, and so makes the initial placement a little more meaningful.\n\nNote also that when a spot is filled with a master, it will always be filled. This is because it either gains a master or gets displaced. This is also clear from looking at the weights of a vertex. If a vertex is positive, it will continue to be positive for the rest of the game.\n\nThis means that the game starts to narrow as there are fewer places to a master.\n\nFor almost all the discussion above, we haven’t needed graph theory, which begs the question why do any of this? For myself, I think it strips out ancillary (yet important details such as theme, etc.) details and gives a mathematical representation that can be manipulated. Viewing a game through the right lense could be suggestive of some design principals.\nFor instance, in the above representation I chose to have the game board be represented as multiple copies, with each copy representing a specific type of master / and it’s corresponding slots.\nThis is interesting because it is suggestive of a game design principle: create independent simple games, and then correlate them / make them interact through a few different actions to add complexity and shared incentives.\nIndeed, you can think of the 7 copies as separate games. The master placement rule requires some colocality of changing a vertex (you can only change a weight 0 vertex to weight 1, if it is at least weight 1 and your color in some copy). And the journey of the students requires evaluating the strength of a village. But after that, the student movements/placements can be treated independently.\nI think this does several different things:\n\nWith the game being similar to 7 independent subgames, some of the reasoning gets simplified (since different types of masters don’t directly interact).\nMaster placement colocality means predicting what an opponent can do is easier. This constraint is useful for making the game more strategic (and also intuitive rules-wise).\nEvaluating the strength of a village directly correlates different types of masters. This allows for shared incentives to emerge with different players.\n\nAnother thing is the game can be viewed very coarsely as a series of edge deletions. This then brings up questions for design, by looking at ablations of mathematical properties:\n\nHow does this game feel if some edges are directed?\nWhat if edge deletion was replaced by other graph operations? For example edge contraction combines two vertices (while removing the edge between them), and retains all the edges coming to/from those vertices. We can mix and match different graph operations and think about how that would influence game play.\nWhat if edges get deleted / removed for different types of masters? Specifically the journey of the students would delete an edge for some subset of the 7 copies of the graph (rather than all of them), so that certain students can still travel.\n\nOverall, by writing a mathematical representation we can get quite a few ideas on how to modify / get inspired to make games that retain some of the feeling of this one."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Srinivas Vasudevan",
    "section": "",
    "text": "Formerly at Google Research.\nBelow is my list of publications. See my Blog for recent writing or Board Games for boardgame design."
  },
  {
    "objectID": "index.html#section",
    "href": "index.html#section",
    "title": "Srinivas Vasudevan",
    "section": "",
    "text": "Formerly at Google Research.\nBelow is my list of publications. See my Blog for recent writing or Board Games for boardgame design."
  },
  {
    "objectID": "index.html#packages",
    "href": "index.html#packages",
    "title": "Srinivas Vasudevan",
    "section": "Packages",
    "text": "Packages\nI’ve worked on libraries in the general ML infrastructure, with a focus on probability and scientific computing\n Eigen,  JAX,  TensorFlow Probability,  TensorFlow"
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "Blog",
    "section": "",
    "text": "Games As Graphs I: Bridges of Shangri-La\n\n\n\nboard-game\n\ngraph-theory\n\n\n\nUnderstanding Board Game Design via Graph Representations\n\n\n\nSrinivas Vasudevan\n\n\nSep 22, 2025\n\n\n\n\n\n\n\n\n\n\n\nTrapezoid Rule Monte Carlo\n\n\n\nmonte-carlo\n\nquadrature\n\n\n\nMixing the Trapezoid Rule with Monte Carlo\n\n\n\nSrinivas Vasudevan\n\n\nSep 19, 2025\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/trapezoid_mc/quad_mc.html",
    "href": "posts/trapezoid_mc/quad_mc.html",
    "title": "Trapezoid Rule Monte Carlo",
    "section": "",
    "text": "I recently encountered a Monte Carlo estimator (Masry and Cambanis 1990) that uses the trapezoid rule and wanted to write out / generalize it.\nGiven a function \\(f\\) (we’ll assume \\(f\\) is \\(C^\\infty\\) for simplicity, but some of these arguments can be changed depending on the smoothness) defined on the unit interval \\([0, 1]\\), we would like to compute the integral \\(I = \\int_0^1 f(x) dx\\). Quadrature methods can easily deal with estimating these integrals 1\nOur plan will be to come up with a lower variance (but biased) estimator, and then generalize to computing integrals of the form \\(\\int_A f(x) p(x) dx\\), where \\(p(x)\\) is a probability density on some subset of \\(\\mathbb{R}\\). Finally, we’ll be able to get an estimator even if we only have access to a sampler and the unnormalized log density (e.g. in the case of MCMC).\nThe typical Monte-Carlo estimator for this type of integral is \\(S_n = \\frac{1}{n}\\sum_{i=1}^n f(u_i)\\), where \\(u_i \\sim U(0, 1)\\) are IID uniform samples. This is an unbiased estimator for \\(I\\) and has variance \\(var(S_n) = \\frac{var(f)}{n}\\), where \\(var(f)\\) is the variance of the random variable \\(f(U), U \\sim U(0, 1)\\). In particular the variance is inversely proportional to \\(n\\)."
  },
  {
    "objectID": "posts/trapezoid_mc/quad_mc.html#trapezoid-rule-estimator",
    "href": "posts/trapezoid_mc/quad_mc.html#trapezoid-rule-estimator",
    "title": "Trapezoid Rule Monte Carlo",
    "section": "Trapezoid Rule Estimator",
    "text": "Trapezoid Rule Estimator\nIf we look at error estimates of various quadrature rules, we see that the errors get better dependency than \\(O(\\frac{1}{\\sqrt n})\\) for estimating \\(I\\).\n\n\nWe can see from the table that we can get errors \\(S_n - I\\) that are at least \\(O(\\frac{1}{n^2})\\) for various Newton-Cotes formula. From wikipedia.\n\n\n\n\n\n\n\nName\nError Bound\n\n\n\n\nTrapezoid Rule\n\\(-\\frac{1}{12n^2}f''(\\xi)\\)\n\n\nSimpson’s \\(\\frac{1}{3}\\) rule Rule\n\\(-\\frac{1}{90n^4}f^{(4)}(\\xi)\\)\n\n\nBoole’s Rule\n\\(-\\frac{8}{945n^6}f^{(6)}(\\xi)\\)\n\n\n\nwhere \\(\\xi\\) lies in the interval of integration \\([a, b]\\).\nThe main idea is we can exploit the structure of the trapezoid rule (and in general Newton-Cotes rules) to get better scaling of the variance with respect to the number of samples \\(n\\).\nGiven \\(n\\) samples \\(u_i \\sim U(0, 1)\\), we can sort the samples to form the order statistics \\(v_i\\). We’ll also add the points \\(0\\) and \\(1\\) to get \\(n + 1\\) points (let \\(v_0 = 0\\) and \\(v_{n + 1} = 1\\)).\nWe can then consider the trapezoid rule estimator: \\(S'_n = \\sum_{i=0}^{n} \\frac{1}{2} (v_{i+1} - v_i)(f(v_{i+1}) + f(v_i))\\)\n\n\n\n\n\n\n\n\n\nFigure 1: Randomized Trapezoid Rule for \\(\\sin(\\frac{\\pi}{2} x)\\)\n\n\n\n\nThe intuition is that for sufficiently smooth \\(f\\), \\(S'_n\\) should be a good estimator of the integral \\(I\\) due to the use of the trapezoid rule. Note that \\(S'_n\\) may be biased, and indeed Figure 1 shows an example of this, where the trapezoid rule approximates the integral well, but will always be an underestimate due to the concavity of the integrand. The hope is that we may trade off some bias for a reduction in variance.\nAs mentioned above, we can note the following deficiencies of this method, compared to quadrature rules and monte carlo rules.\n\nThis can be a biased estimator.\nThis is for \\(U(0, 1)\\) random variables and in one dimension, for which there are better methods.\nIn the current formulation, you have to evaluate the endpoints \\(0\\) and \\(1\\). This can be problematic for integrands (such as certain \\(Beta(\\alpha, \\beta)\\) densities which go off to \\(\\infty\\) in the tails). We can actually get away with \\(n\\) points without evaluating the \\(0\\) and \\(1\\) points. Adding the points just simplifies the analysis and reduces the error by a constant."
  },
  {
    "objectID": "posts/trapezoid_mc/quad_mc.html#error-bound-on-s_n",
    "href": "posts/trapezoid_mc/quad_mc.html#error-bound-on-s_n",
    "title": "Trapezoid Rule Monte Carlo",
    "section": "Error bound on \\(S'_n\\)",
    "text": "Error bound on \\(S'_n\\)\nLet’s take a look at the error \\(S'_n - I\\).\nFor simplicity we’ll reuse a form of the Trapezoid Rule Error 2.\n2 See hereIf we are estimating \\(\\int_{v_i}^{v_{i+1}} f(x) dx\\), then the error of using \\(\\frac{1}{2}(f(v_{i+1}) + f(v_{i}))(v_{i+1} - v_i)\\) is bounded by \\(\\frac{K_i(v_{i+1} - v_i)^3}{12}\\), where \\(K_i = \\sup_{[v_i, v_{i+1}]} |f''(x)|\\) (this can be derived through repeated applications of the Mean Value Theorem).\n\\(|S'_n - I| = |-\\int_0^1 f(x) dx + \\sum_{i=0}^{n}\\frac{1}{2}(v_{i+1} - v_i) (f(v_{i+1}) - f(v_i))|\\)\n\\(=|\\sum_{i=0}^{n}\\frac{1}{2}(v_{i+1} - v_i) (f(v_{i+1}) + f(v_i)) - \\int_{v_i}^{v_{i+1}} f(x) dx|\\)\n\\(\\le\\sum_{i=0}^{n}|\\frac{1}{2}(v_{i+1} - v_i) (f(v_{i+1}) + f(v_i)) - \\int_{v_i}^{v_{i+1}} f(x) dx|\\)\n\\(\\le\\sum_{i=0}^{n}\\frac{K_i}{12}(v_{i + 1} - v_i)^3\\)\n\\(\\le\\frac{K}{12}\\sum_{i=0}^{n}(v_{i + 1} - v_i)^3\\)\nLet \\(x_i = v_{i+1} - v_i\\). It’s well known that these lengths are jointly distributed like a Dirichlet 3.\n3 See hereThis makes the \\((x_0, ... , x_{n}) \\sim Dirichlet(1, 1, ...., 1)\\)\nWe’ll use the following properties of moments of the Dirichlet distribution (n.d.).\n\nLin, Jiayu. n.d. “On the Dirichlet Distribution.” https://mast.queensu.ca/~communications/Papers/msc-jiayu-lin.pdf.\n\\(\\mathbb{E}[X_i^k] = \\frac{\\Gamma(n)}{\\Gamma(n + k)} \\frac{\\Gamma(k + 1)}{\\Gamma(1)} = \\frac{(n - 1)!k!}{(n + k - 1)!} = \\frac{k!}{n (n + 1) (n + 2) ... (n + k - 1)}\\) \\(\\mathbb{E}[X_i^kX_j^k] = \\frac{\\Gamma(n)}{\\Gamma(n + 2k)} \\frac{\\Gamma(k + 1)^2}{\\Gamma(1)} = \\frac{(n - 1)!(k!)^2}{(n + 2k - 1)!} = \\frac{k!^2}{n (n + 1) (n + 2) ... (n + 2k - 1)}\\)\nThat is the \\(k\\)-th marginal moment grows like \\(O(\\frac{1}{n^k})\\). and that the mixed moment \\(\\mathbb{E}[X_i^kX_j^k]\\) grows like \\(O(\\frac{1}{n^{2k}})\\).\nWe can look at \\(\\mathbb{E}[(S'_n - I)^2] = \\mathbb{E}[(\\frac{K}{12})^2 (\\sum_{i=0}^{n + 1}(x_i)^3)^2]\\) = \\(\\frac{K^2}{144}\\sum_{i, j} \\mathbb{E}[x_i^3x_j^3]\\)\nAs the sum over the \\((n + 2)^2\\) terms is over moments which are all \\(O(\\frac{1}{n^6})\\), this results in \\(\\mathbb{E}[(S'_n - I)^2)] = O(\\frac{1}{n^4})\\) (with an \\(O(\\frac{1}{n^2})\\) bound on the bias) 4. A precise bound can be derived by carrying through the constants from the Trapezoid Rule and the Dirichlet moments.\n4 One can easily get an error bound on the bias \\(|\\mathbb{E}[S'_n - I]|\\) without squaring the sum. Mainly looking at \\(\\mathbb{E}[(S'_n - I)^2]\\) gives us a stronger form of convergence, and one can still recover a bound on the bias."
  },
  {
    "objectID": "posts/trapezoid_mc/quad_mc.html#examples",
    "href": "posts/trapezoid_mc/quad_mc.html#examples",
    "title": "Trapezoid Rule Monte Carlo",
    "section": "Examples",
    "text": "Examples\nHere’s some example on a few different functions on \\([0, 1]\\)\n\n\\(f = \\frac{1}{1 + x^2}\\)\n\\(g = e^x\\sin(\\frac{x}{2})\\)\n\\(h = x^3 - x + x^2\\).\n\n\n\n\n\nTable 1: Absolute Error in estimating the integral of \\(f = \\frac{1}{1 + x^2}\\), \\(g = e^x \\sin(\\frac{x}{2})\\), \\(h = x^3 - x + x^2\\).\n\n\n\n\n\n\n\n\nIntegral\nMethod\nN=10\nN=50\nN=100\nN=200\nN=1000\n\n\n\n\n0.785398\nMonte Carlo\n0.026491\n0.019358\n0.008144\n0.002608\n0.001540\n\n\n0.785398\nTrapezoid Rule\n0.000393\n0.000010\n0.000038\n0.000009\n0.000000\n\n\n0.785398\nSimpson's 1/3 Rule\n0.000002\n0.000010\n0.000001\n0.000000\n0.000000\n\n\n\n\n\n\n\n\n\n\nIntegral\nMethod\nN=10\nN=50\nN=100\nN=200\nN=1000\n\n\n\n\n0.488364\nMonte Carlo\n0.146778\n0.003383\n0.026795\n0.034787\n0.009164\n\n\n0.488364\nTrapezoid Rule\n0.005188\n0.000636\n0.000118\n0.000022\n0.000001\n\n\n0.488364\nSimpson's 1/3 Rule\n0.000131\n0.000002\n0.000000\n0.000000\n0.000000\n\n\n\n\n\n\n\n\n\n\nIntegral\nMethod\nN=10\nN=50\nN=100\nN=200\nN=1000\n\n\n\n\n0.083333\nMonte Carlo\n0.178741\n0.057350\n0.007101\n0.011000\n0.000868\n\n\n0.083333\nTrapezoid Rule\n0.011265\n0.001467\n0.000173\n0.000051\n0.000002\n\n\n0.083333\nSimpson's 1/3 Rule\n0.004317\n0.000017\n0.000001\n0.000000\n0.000000\n\n\n\n\n\n\n\n\nWe can see that the error of the estimates from the Trapezoid Monte Carlo estimator seem to decrease very rapidly."
  },
  {
    "objectID": "posts/trapezoid_mc/quad_mc.html#improving-the-estimator",
    "href": "posts/trapezoid_mc/quad_mc.html#improving-the-estimator",
    "title": "Trapezoid Rule Monte Carlo",
    "section": "“Improving” the Estimator",
    "text": "“Improving” the Estimator\nThe above estimator can be extended to other Newton-Cotes-type estimators. A Newton-Cotes formula is an integration rule that estimates the integral via the integration of a polynomial interpolant on \\(k + 1\\) equally spaced points.\nFor instance, the trapezoid rule is just the integral of the linear polynomial between two equally spaced points.\nFor our purposes, we can take the interpolant and use it to derive an integration rule on non-qequally spaced points.\nA Simpson’s Rule-type estimator, for instance would be of order 2 and use the \\(3\\) points next to each other (as seen in Figure 2).\n\n\n\n\n\n\n\n\n\nFigure 2: Randomized Simpson Rule for \\(\\sin(2 \\pi x)\\)\n\n\n\n\nThe interpolating polynomial through the ordered points \\(a, b, c\\) would be \\(p(x) = f(a)\\frac{(c - x)(b - x)}{(c - a)(b - a)} + f(b)\\frac{(c - x)(a - x)}{(c - b)(a - c)} + f(c)\\frac{(a - x)(b - x)}{(a - c)(b - c)}\\).\nThen \\(\\int_a^c p(x) dx = -\\frac{(a - c)(f(b)(a - c)^2 + f(a)(c - b)(2(b - a) - (c - b)) + f(c)(b - a)(2(c - b) - (b - a)))}{6(b - a)(c - b)}\\)\nIf we call this result \\(g(a, b, c)\\), then we can form the estimator\n\\(S''_n = \\sum_{i=0}^{\\frac{n - 1}{2}} g(v_{2i}, v_{2i+1}, v_{2i+2})\\)\nError analysis for this can proceed in a similar way (though very messily), which should result in an estimator with \\(\\mathbb{E}[(S''_n - I)^2] = O(\\frac{1}{n^8})\\). Similary we should have a \\(O(\\frac{1}{n^4})\\) bound on the bias.\nIn general, we can set up estimators from larger interpolating polynomials, to get asymptotically faster converging estimators 56.\n5 Note that polynomial interpolation on equally spaced points can be very numerically unstable. These estimators defend against this by being on random points, but some care needs to be taken.6 Note that while the Dirichlet moments will decay faster in \\(n\\) for higher order interpolants, they also pick up larger constants.As seen in Table 1, we empirically get faster convergence with the Simpson’s-rule type estimator."
  },
  {
    "objectID": "posts/trapezoid_mc/quad_mc.html#extending-to-other-probability-distributions",
    "href": "posts/trapezoid_mc/quad_mc.html#extending-to-other-probability-distributions",
    "title": "Trapezoid Rule Monte Carlo",
    "section": "Extending to other probability distributions",
    "text": "Extending to other probability distributions\nSuppose now we have \\(\\int_{[a, b]} f(x) p(x) dx\\), where \\(p(x)\\) is some probability density on some interval \\([a, b]\\)\nThe Monte Carlo estimate would be \\(\\sum_{i=0}^{n-1} f(x_i)\\), where \\(x_i \\sim p(x)\\). We would like to use our trapezoid estimator here, where we now have samples from \\(p(x)\\) rather than uniform samples.\nWe can naively apply the estimator by computing order statistics of \\(x_i\\), called \\(z_i\\), appending \\(a\\) and \\(b\\) to the ends much like before.\nThis gives the estimator \\(S'_n = \\sum_{i=0}^n \\frac{1}{2}(z_{i+1} - z_i) (f(z_{i+1})p(z_{i+1}) - f(z_i)p(z_i))\\)\nLet \\(v_i = F(z_i)\\), where \\(F\\) is the CDF (we’ll assume this is completely differentiable). Then we have\n\\(S'_n = \\sum_{i=0}^n \\frac{1}{2}(z_{i+1} - z_i) (f(z_{i+1})p(z_{i+1}) - f(z_i)p(z_i)))\\)\n\\(= \\sum_{i=0}^n \\frac{1}{2}(F^{-1}(v_{i+1})- F^{-1}(v_i)) (f(F^{-1}(v_{i+1}))p(F^{-1}(v_{i+1})) - f(F^{-1}(v_i))p(F^{-1}(v_{i+1})))\\)\nVia an application of the Mean Value Theorem we have: \\(S'_n = \\sum_{i=0}^n \\frac{1}{2}F'^{-1}(s_i) (v_{i+1} - v_i)(f(F^{-1}(v_{i+1}))p(F^{-1}(v_{i+1})) - f(F^{-1}(v_i))p(F^{-1}(v_i)))\\)\nfor some \\(s_i \\in [v_i, v_{i+1}]\\)\nThis suggests that if \\(\\sup_{[0, 1]} |F'^{-1}(u)|  = \\sup_{[a, b]} \\frac{1}{p(x)} &lt; \\infty\\), then we can pick up another constant and proceed with our error analysis as before, and thus get a \\(O(\\frac{1}{n^4})\\) bound on \\(\\mathbb{E}[(I - S'_n)^2]\\). More careful treatment in something like Phillipe (1997) can loosen this restriction.\nWe can apply this rule to a Beta density \\(p(x)\\) of a \\(Beta(2, 3)\\) random variable, with our functions from Table 1 to estimate \\(\\int_0^1 f(x)p(x) dx\\).\n\n\n\n\nTable 2: Absolute Error in estimating the integral of \\(f = \\frac{1}{1 + x^2}\\), \\(g = e^x \\sin(\\frac{x}{2})\\), \\(h = x^3 - x + x^2\\) with respect to the Beta distribution.\n\n\n\n\n\n\n\n\nIntegral\nMethod\nN=10\nN=50\nN=100\nN=200\nN=1000\n\n\n\n\n0.849556\nMonte Carlo\n0.022431\n0.015612\n0.006972\n0.006267\n0.003704\n\n\n0.849556\nTrapezoid Rule\n0.071244\n0.004386\n0.001175\n0.003429\n0.000172\n\n\n0.849556\nSimpson's 1/3 Rule\n0.021684\n0.000002\n0.000070\n0.000004\n0.000000\n\n\n\n\n\n\n\n\n\n\nIntegral\nMethod\nN=10\nN=50\nN=100\nN=200\nN=1000\n\n\n\n\n0.331193\nMonte Carlo\n0.047922\n0.032177\n0.012697\n0.005025\n0.003999\n\n\n0.331193\nTrapezoid Rule\n0.000814\n0.001131\n0.005256\n0.001520\n0.000146\n\n\n0.331193\nSimpson's 1/3 Rule\n0.011204\n0.000972\n0.001880\n0.001769\n0.000013\n\n\n\n\n\n\n\n\n\n\nIntegral\nMethod\nN=10\nN=50\nN=100\nN=200\nN=1000\n\n\n\n\n-0.085714\nMonte Carlo\n0.061996\n0.014922\n0.000664\n0.006580\n0.001264\n\n\n-0.085714\nTrapezoid Rule\n0.009933\n0.001845\n0.000278\n0.000761\n0.000123\n\n\n-0.085714\nSimpson's 1/3 Rule\n0.015353\n0.000206\n0.001751\n0.001618\n0.000059\n\n\n\n\n\n\n\n\nAs seen in Table 2, we can still outperform the naive Monte-Carlo estimator.\nIf we only have access to an unnormalized density \\(h(x)\\), \\(\\frac{h(x)}{Z} = p(x)\\), an application of Slutsky’s Theorem gives us the following estimator (where we simultaneously estimate the normalizing constant \\(Z\\)):\n\\(S'_n = \\frac{\\sum_{i=0}^n \\frac{1}{2}(z_{i+1} - z_i) (f(z_{i+1})h(z_{i+1}) - f(z_i)h(z_i))}{\\sum_{i=0}^n \\frac{1}{2}(z_{i+1} - z_i) (h(z_{i+1}) - h(z_i))}\\)\nThus, given a non-zero unnormalized density on \\([a, b]\\) and access to a sampler, we can estimate an expectation to any smooth function with this estimator 7.\n7 In general we can mix and match estimators for the normalizing constant in the denominator. These estimators will be consistent, but in general will not be unbiased."
  },
  {
    "objectID": "posts/trapezoid_mc/quad_mc.html#other",
    "href": "posts/trapezoid_mc/quad_mc.html#other",
    "title": "Trapezoid Rule Monte Carlo",
    "section": "Other",
    "text": "Other\nThis type of estimator seems to have been originally derived from Yakowitz and Szidarovszky (1978) for the unit interval. Phillipe (1997) and related works extend the Riemann sum estimator to other distributions.\n\n\n\nYakowitz, Krimmel, S., and F. Szidarovszky. 1978. “Weighted Monte Carlo Integration.” SIAM Journal on Numerical Analysis 15 (6): 1289–1300.\n\nPhillipe, Anne. 1997. “Importance Sampling and Riemann Sums.” Publications IRMA Université de Lille 43 (IV)."
  },
  {
    "objectID": "publications/index.html",
    "href": "publications/index.html",
    "title": "Research",
    "section": "",
    "text": "Xingyou Song, Qiuyi Zhang, Chansoo Lee, Emily Fertig, Tzu-Kuo Huang, Lior Belinski, Greg Kochanski, Setareh Ariafar, Srinivas Vasudevan, Sagi Perel, Daniel Golovin\n                Aug 21, 2024\n                The Vizier Gaussian Process Bandit Algorithm\n                \n                \n                \n            \n            \n\n            \n                \n                    \n                        \n                    \n                        \n                        \n                        \n                             \n                             Arxiv\n                        \n                    \n                        \n                    \n                \n            \n        \n        \n        \n            \n                Thomas Colthurst, Srinivas Vasudevan, James Lottes, Brian Patton\n                May 6, 2024\n                Fast Approximate Determinants Using Rational Functions\n                \n            \n            \n\n            \n                \n                    \n                        \n                    \n                        \n                        \n                        \n                             \n                             Arxiv\n                        \n                    \n                        \n                    \n                \n            \n        \n        \n        \n            \n                Colin Carrol, Thomas Colthurst, Urs Koster, Srinivas Vasudevan\n                Mar 28, 2024\n                AutoBNN: Probabilistic time series forecasting with compositional bayesian neural networks\n                \n            \n            \n\n            \n                \n                    \n                        \n                    \n                        \n                        \n                        \n                             \n                             Google Research\n                        \n                    \n                        \n                    \n                \n            \n        \n        \n        \n            \n                Erik Nijkamp, Ruiqi Gao, Pavel Sountsov, Srinivas Vasudevan, Bo Pang, Song-Chun Zhu, Ying Nian Wu\n                Jun 12, 2020\n                MCMC should mix: Learning energy-based model with neural transport latent space MCMC\n                \n            \n            \n\n            \n                \n                    \n                        \n                    \n                        \n                        \n                        \n                             \n                             Arxiv\n                        \n                    \n                        \n                    \n                \n            \n        \n        \n        \n            \n                Pavel Sountsov, Alexy Radul, Srinivas Vasudevan\n                Jan 14, 2020\n                FunMC: A function API for building Markov Chains\n                \n            \n            \n\n            \n                \n                    \n                        \n                    \n                        \n                        \n                        \n                             \n                             Arxiv\n                        \n                    \n                        \n                    \n                \n            \n        \n        \n        \n            \n                Matthew Hoffman, Pavel Sountsov, Joshua V Dillon, Ian Langmore, Dustin Tran, Srinivas Vasudevan\n                Mar 9, 2019\n                Neutra-lizing bad geometry in hamiltonian monte carlo using neural transport\n                \n            \n            \n\n            \n                \n                    \n                        \n                    \n                        \n                        \n                        \n                             \n                             Arxiv\n                        \n                    \n                        \n                    \n                \n            \n        \n        \n        \n            \n                Dustin Tran, Matthew W Hoffman, Dave Moore, Christopher Suter, Srinivas Vasudevan, Alexey Radul\n                Nov 5, 2018\n                Simple, distributed, and accelerated probabilitic programming\n                \n            \n            \n\n            \n                \n                    \n                        \n                    \n                        \n                        \n                        \n                             \n                             Arxiv\n                        \n                    \n                        \n                    \n                        \n                        \n                        \n                             \n                             Neurips'18\n                        \n                    \n                        \n                    \n                \n            \n        \n        \n        \n            \n                Joshua V. Dillon, Ian Langmore, Dustin Tran, Eugene Brevdo, Srinivas Vasudevan, Dave Moore, Brian Patton, Alex Alemi, Matt Hoffman, Rif A Sauros\n                Nov 28, 2017\n                Tensorflow distributions\n                \n            \n            \n\n            \n                \n                    \n                        \n                    \n                        \n                        \n                        \n                             \n                             Arxiv\n                        \n                    \n                        \n                    \n                \n            \n        \n        \n\n\nNo matching items"
  },
  {
    "objectID": "boardgames/index.html",
    "href": "boardgames/index.html",
    "title": "Board Games",
    "section": "",
    "text": "Bitesize\n                    Designers: Srinivas Vasudevan\n                    Player Count: 2\n                    A simple must-not-follow domino climbing-shedding game.\n                  \n                  \n                \n            \n            \n            \n                \n                    \n                            domino\n                        \n                    \n                    \n                            climbing\n                        \n                    \n                    \n                            shedding\n                        \n                    \n            \n            \n\n            \n                \n                    \n                    \n                        \n                             BGG\n                        \n                    \n                    \n                \n            \n        \n        \n        \n            \n                \n                  \n                    Carvers Park\n                    Designers: DJ Kenel, Srinivas Vasudevan\n                    Player Count: 3-4\n                    A climbing-shedding game with speed limits and ranks reversing each trick.\n                  \n                  \n                  \n                  \n                \n            \n            \n            \n                \n                    \n                            domino\n                        \n                    \n                    \n                            climbing\n                        \n                    \n                    \n                            shedding\n                        \n                    \n            \n            \n\n            \n                \n                    \n                    \n                        \n                             BGG\n                        \n                    \n                    \n                \n            \n        \n        \n        \n            \n                \n                  \n                    Lepidoptery\n                    Designers: David Karesh, Srinivas Vasudevan\n                    Player Count: 2\n                    A climbing-shedding game crossed with Connect 4.\n                  \n                  \n                  \n                  \n                \n            \n            \n            \n                \n                    \n                            climbing\n                        \n                    \n                    \n                            shedding\n                        \n                    \n            \n            \n\n            \n                \n                    \n                    \n                        \n                             BGG\n                        \n                    \n                    \n                \n            \n        \n        \n        \n            \n                \n                  \n                    Pikel\n                    Designers: Srinivas Vasudevan\n                    Player Count: 2\n                    A may-follow domino climbing-shedding game, where you can't rearrange your hand.\n                  \n                  \n                \n            \n            \n            \n                \n                    \n                            domino\n                        \n                    \n                    \n                            climbing\n                        \n                    \n                    \n                            shedding\n                        \n                    \n            \n            \n\n            \n                \n                    \n                    \n                        \n                             BGG\n                        \n                    \n                    \n                \n            \n        \n        \n        \n            \n                \n                  \n                    Zipper\n                    Designers: David Karesh, Srinivas Vasudevan\n                    Player Count: 2\n                    A domino climbing-shedding game with a preorder.\n                  \n                  \n                \n            \n            \n            \n                \n                    \n                            domino\n                        \n                    \n                    \n                            climbing\n                        \n                    \n                    \n                            shedding\n                        \n                    \n            \n            \n\n            \n                \n                    \n                    \n                        \n                             BGG\n                        \n                    \n                    \n                \n            \n        \n        \n\n\nNo matching items"
  }
]