[
  {
    "objectID": "boardgames/index.html",
    "href": "boardgames/index.html",
    "title": "Board Games",
    "section": "",
    "text": "Bitesize\n                    Designers: Srinivas Vasudevan\n                    Player Count: 2\n                    A simple must-not-follow domino climbing-shedding game.\n                  \n                  \n                  \n                  \n                \n            \n            \n            \n                \n                    \n                            domino\n                        \n                    \n                    \n                            climbing\n                        \n                    \n                    \n                            shedding\n                        \n                    \n            \n            \n\n            \n                \n                    \n                    \n                        \n                             BGG\n                        \n                    \n                    \n                \n            \n        \n        \n        \n            \n                \n                  \n                    Carvers Park\n                    Designers: DJ Kenel, Srinivas Vasudevan\n                    Player Count: 3-4\n                    A climbing-shedding game with speed limits and ranks reversing each trick.\n                  \n                  \n                  \n                  \n                \n            \n            \n            \n                \n                    \n                            domino\n                        \n                    \n                    \n                            climbing\n                        \n                    \n                    \n                            shedding\n                        \n                    \n            \n            \n\n            \n                \n                    \n                    \n                        \n                             BGG\n                        \n                    \n                    \n                \n            \n        \n        \n        \n            \n                \n                  \n                    Lepidoptery\n                    Designers: David Karesh, Srinivas Vasudevan\n                    Player Count: 2\n                    A climbing-shedding game crossed with Connect 4.\n                  \n                  \n                  \n                  \n                \n            \n            \n            \n                \n                    \n                            climbing\n                        \n                    \n                    \n                            shedding\n                        \n                    \n            \n            \n\n            \n                \n                    \n                    \n                        \n                             BGG\n                        \n                    \n                    \n                \n            \n        \n        \n        \n            \n                \n                  \n                    Pikel\n                    Designers: Srinivas Vasudevan\n                    Player Count: 2\n                    A may-follow domino climbing-shedding game with a fixed hand.\n                  \n                  \n                  \n                  \n                \n            \n            \n            \n                \n                    \n                            domino\n                        \n                    \n                    \n                            climbing\n                        \n                    \n                    \n                            shedding\n                        \n                    \n            \n            \n\n            \n                \n                    \n                    \n                        \n                             BGG\n                        \n                    \n                    \n                \n            \n        \n        \n        \n            \n                \n                  \n                    Syzygy\n                    Designers: David Karesh, Srinivas Vasudevan\n                    Player Count: 2\n                    A domino climbing-shedding with stateful must-not-follow.\n                  \n                  \n                  \n                  \n                \n            \n            \n            \n                \n                    \n                            climbing\n                        \n                    \n                    \n                            shedding\n                        \n                    \n            \n            \n\n            \n                \n                    \n                    \n                        \n                             BGG\n                        \n                    \n                    \n                \n            \n        \n        \n        \n            \n                \n                  \n                    Zipper\n                    Designers: David Karesh, Srinivas Vasudevan\n                    Player Count: 2\n                    A domino climbing-shedding game with a preorder.\n                  \n                  \n                  \n                  \n                \n            \n            \n            \n                \n                    \n                            domino\n                        \n                    \n                    \n                            climbing\n                        \n                    \n                    \n                            shedding\n                        \n                    \n            \n            \n\n            \n                \n                    \n                    \n                        \n                             BGG\n                        \n                    \n                    \n                \n            \n        \n        \n\n\nNo matching items"
  },
  {
    "objectID": "publications/index.html",
    "href": "publications/index.html",
    "title": "Research",
    "section": "",
    "text": "Xingyou Song, Qiuyi Zhang, Chansoo Lee, Emily Fertig, Tzu-Kuo Huang, Lior Belinski, Greg Kochanski, Setareh Ariafar, Srinivas Vasudevan, Sagi Perel, Daniel Golovin\n                Aug 21, 2024\n                The Vizier Gaussian Process Bandit Algorithm\n                \n                \n                \n            \n            \n\n            \n                \n                    \n                        \n                    \n                        \n                        \n                        \n                             \n                             Arxiv\n                        \n                    \n                        \n                    \n                \n            \n        \n        \n        \n            \n                Thomas Colthurst, Srinivas Vasudevan, James Lottes, Brian Patton\n                May 6, 2024\n                Fast Approximate Determinants Using Rational Functions\n                \n            \n            \n\n            \n                \n                    \n                        \n                    \n                        \n                        \n                        \n                             \n                             Arxiv\n                        \n                    \n                        \n                    \n                \n            \n        \n        \n        \n            \n                Colin Carrol, Thomas Colthurst, Urs Koster, Srinivas Vasudevan\n                Mar 28, 2024\n                AutoBNN: Probabilistic time series forecasting with compositional bayesian neural networks\n                \n            \n            \n\n            \n                \n                    \n                        \n                    \n                        \n                        \n                        \n                             \n                             Google Research\n                        \n                    \n                        \n                    \n                \n            \n        \n        \n        \n            \n                Erik Nijkamp, Ruiqi Gao, Pavel Sountsov, Srinivas Vasudevan, Bo Pang, Song-Chun Zhu, Ying Nian Wu\n                Jun 12, 2020\n                MCMC should mix: Learning energy-based model with neural transport latent space MCMC\n                \n            \n            \n\n            \n                \n                    \n                        \n                    \n                        \n                        \n                        \n                             \n                             Arxiv\n                        \n                    \n                        \n                    \n                \n            \n        \n        \n        \n            \n                Pavel Sountsov, Alexy Radul, Srinivas Vasudevan\n                Jan 14, 2020\n                FunMC: A function API for building Markov Chains\n                \n            \n            \n\n            \n                \n                    \n                        \n                    \n                        \n                        \n                        \n                             \n                             Arxiv\n                        \n                    \n                        \n                    \n                \n            \n        \n        \n        \n            \n                Matthew Hoffman, Pavel Sountsov, Joshua V Dillon, Ian Langmore, Dustin Tran, Srinivas Vasudevan\n                Mar 9, 2019\n                Neutra-lizing bad geometry in hamiltonian monte carlo using neural transport\n                \n            \n            \n\n            \n                \n                    \n                        \n                    \n                        \n                        \n                        \n                             \n                             Arxiv\n                        \n                    \n                        \n                    \n                \n            \n        \n        \n        \n            \n                Dustin Tran, Matthew W Hoffman, Dave Moore, Christopher Suter, Srinivas Vasudevan, Alexey Radul\n                Nov 5, 2018\n                Simple, distributed, and accelerated probabilitic programming\n                \n            \n            \n\n            \n                \n                    \n                        \n                    \n                        \n                        \n                        \n                             \n                             Arxiv\n                        \n                    \n                        \n                    \n                        \n                        \n                        \n                             \n                             Neurips'18\n                        \n                    \n                        \n                    \n                \n            \n        \n        \n        \n            \n                Joshua V. Dillon, Ian Langmore, Dustin Tran, Eugene Brevdo, Srinivas Vasudevan, Dave Moore, Brian Patton, Alex Alemi, Matt Hoffman, Rif A Sauros\n                Nov 28, 2017\n                Tensorflow distributions\n                \n            \n            \n\n            \n                \n                    \n                        \n                    \n                        \n                        \n                        \n                             \n                             Arxiv\n                        \n                    \n                        \n                    \n                \n            \n        \n        \n\n\nNo matching items"
  },
  {
    "objectID": "posts/counting_abelian_groups/counting_abelian_groups.html",
    "href": "posts/counting_abelian_groups/counting_abelian_groups.html",
    "title": "Counting the number of abelian groups",
    "section": "",
    "text": "As an undergraduate, I got exposed to group theory and notably the classification of finite abelian groups 1. I have recently thought about how to count asymptotically the number of these groups up to isomorphism. It turns out this problem was originally solved by Erdos and Szekeres2, and we’’ll try to summarize an argument for the first order asymptotics here.\nThe main ideas of this proof are:"
  },
  {
    "objectID": "posts/counting_abelian_groups/counting_abelian_groups.html#review-whirlwind-group-theory",
    "href": "posts/counting_abelian_groups/counting_abelian_groups.html#review-whirlwind-group-theory",
    "title": "Counting the number of abelian groups",
    "section": "Review: Whirlwind Group Theory",
    "text": "Review: Whirlwind Group Theory\nFirst, recall a group \\(G\\) is a set equipped with an operation \\(*\\), satisfying the following axioms:\n\nClosure: \\(a * b \\in G,\\, \\forall a, b \\in G\\)\nAssociativity: \\((a * b) * c = a * (b * c),\\, \\forall a, b, c \\in G\\)\nIdentity: \\(\\exists e \\in G,\\, \\text{s.t.}\\, \\forall a \\in G,\\, e * a = a * e = a\\)\nInverse: \\(\\forall a \\in G,\\, \\exists a^{-1} \\in G,\\, \\text{s.t.} \\,a^{-1} * a = a * a^{-1} = e\\)\n\nA commutative group satisfies the following additional axiom\n\nCommutativity: \\(a * b = b * a,\\, \\forall a, b \\in G\\).\n\nSince a group is a set \\(G\\), we can look at the cardinality of the set \\(|G|\\). A finite group is one where \\(|G| &lt; \\infty\\) and the order of a group is simply this number \\(ord(G) = |G|\\).\nWhat we are interested in is how many finite abelian groups up to isomorphism have order \\(n\\). We’ll call this \\(a(n)\\). Figure 1 plots \\(a(n)\\) for orders 1 to 10000.\nWe can see that the number varies a lot, and unclear if it even grows. In particular if \\(ord(G) = p\\) for a prime \\(p\\), there is only one group of that order, \\(\\mathbb{Z}/p\\mathbb{Z}\\) the cyclic group of order \\(p\\). That is, \\(a(p) = 1\\) for all primes \\(p\\), so it dips to 1 infinitely often.\nWhat we might care about instead is a smoothed version of this \\(\\frac{1}{x}\\sum_{n \\le x} a(n)\\), which represents the average value of \\(a(n)\\). Figure 1 shows that this seems to be grow but asymptote around a little over \\(2\\). In fact as proven by Erdos and Szekeres we’ll have\n\\[\\sum_{n \\le x} a(n) \\sim \\prod_{k=2}^\\infty \\zeta(k) x\\]\nWhere \\(\\zeta\\) is the Riemann Zeta function. This constant in front is roughly \\(2.29\\), and is represented by the blue line in the plot.\n\n\n\n\n\n\n\n\nFigure 1: Number of abelian groups of order N.\n\n\n\n\nNumber of Abelian Groups of order N"
  },
  {
    "objectID": "posts/counting_abelian_groups/counting_abelian_groups.html#structure-of-an.",
    "href": "posts/counting_abelian_groups/counting_abelian_groups.html#structure-of-an.",
    "title": "Counting the number of abelian groups",
    "section": "Structure of \\(a(n)\\).",
    "text": "Structure of \\(a(n)\\).\nThe fundamental theorem of finite abelian groups says that every finite abelian group can be written in the form \\(\\mathbb{Z}/p_1^{k_1}\\mathbb{Z} \\times \\mathbb{Z}/p_2^{k_2}\\mathbb{Z} \\times \\mathbb{Z}/p_3^{k_3}\\mathbb{Z} \\ldots \\mathbb{Z}/p_n^{k_n}\\mathbb{Z}\\) where \\(p_i\\) are primes, not necessarily distinct, and \\(k_i \\in \\mathbb{N}\\). 3\n3 In fact each \\(p_i\\) must appear in the prime factorization of \\(ord(G)\\).Recall that a finite \\(p\\)-group is which has prime power order \\(ord(G) = p^k\\) for some prime \\(p\\), and natural number \\(k\\).\nWe can group the factors into \\(P_1, \\ldots P_m\\), where \\(P_i\\) is a product of factors containing the same prime. That is, every finite abelian group can be written as \\(P_1 \\times P_2 \\times \\ldots P_m\\), where \\(P_i\\) are abelian \\(q_i\\)-groups, with the \\(q_i\\) distinct. The order of such a group \\(G\\) is \\(ord(G) = ord(P_1)ord(P_2)\\ldots ord(P_m)\\).\nThis is suggestive that if we are looking at \\(a(n)\\), we should look at the prime factorization of \\(n = p_1^{k_1}p_2^{k_2}\\ldots p_m^{k_m}\\). For any abelian group of order \\(n\\) it will have factors \\(P_1 \\times P_2 \\ldots \\times P_m\\), where \\(P_i\\) is a \\(p_i\\)-group of order \\(p_i^{k_i}\\). Then, we will have \\(a(n) = a(p_1^{k_1})a(p_2^{k_2})\\ldots a(p_m^{k_m})\\). In other words \\(a(n)\\) is a multiplicative function!\n\n\\(a(p^k)\\)\nNow, given a prime \\(p\\), we want to count the number of abelian groups of order \\(p^k\\), for some \\(k \\in \\mathbb{N}\\). We can enumerate a few cases to see a pattern.\nFor \\(k = 1\\), we have only one group, since \\(\\mathbb{Z}/p\\mathbb{Z}\\) is simple. \\(a(p) = 1\\)\nFor \\(k = 2\\) we have two groups: \\(\\mathbb{Z}/p^2\\mathbb{Z}\\) and \\(\\mathbb{Z}/p\\mathbb{Z} \\times \\mathbb{Z} / p\\mathbb{Z}\\). \\(a(p^2) = 2\\)\nFor \\(k = 3\\) we have three groups: \\(\\mathbb{Z}/p^3\\mathbb{Z}\\), \\(\\mathbb{Z}/p^2\\mathbb{Z} \\times \\mathbb{Z}/p\\mathbb{Z}\\) and \\(\\mathbb{Z}/p\\mathbb{Z} \\times \\mathbb{Z}/p\\mathbb{Z} \\times \\mathbb{Z}/p\\mathbb{Z}\\). \\(a(p^3) = 3\\)\nWhat we’ve done above is take \\(p^k\\) and look at ways to partition \\(k\\).\nFor instance, the 11 partitions of \\(6\\) are:\n1 + 1 + 1 + 1 + 1 + 1\n2 + 1 + 1 + 1 + 1\n2 + 2 + 1 + 1\n3 + 1 + 1 + 1\n2 + 2 + 2\n3 + 2 + 1\n4 + 1 + 1\n3 + 3\n4 + 2\n5 + 1\n6\nWe can then arrange factors based of that partition. If we take \\([3, 2, 1]\\), then we have \\(\\mathbb{Z}/p^3\\mathbb{Z} \\times \\mathbb{Z}/p^2\\mathbb{Z} \\times \\mathbb{Z}/p\\mathbb{Z}\\).\nLikewise, given any factorization of the \\(p\\)-group, we can order the factors in descending order and show that forms a partition of \\(6\\). Thus, \\(a(p^6) = 11\\), and more generally \\(a(p^k) = p(k)\\) where \\(p(k)\\) is the number of partitions of \\(k\\)."
  },
  {
    "objectID": "posts/counting_abelian_groups/counting_abelian_groups.html#dirichlet-generating-function",
    "href": "posts/counting_abelian_groups/counting_abelian_groups.html#dirichlet-generating-function",
    "title": "Counting the number of abelian groups",
    "section": "Dirichlet Generating Function",
    "text": "Dirichlet Generating Function\nGiven that \\(a(n)\\) is a multiplicative function, it’s suggestive to look at \\(f(s) = \\sum_{i=1}^\\infty \\frac{a(n)}{n^s}\\), at least formally. Since \\(a(n)\\) is multiplicative, it has an Euler product expansion \\(f(s) = \\prod_p \\sum_{k=0}^\\infty \\frac{a(p^k)}{p^{sk}} = \\prod_p \\sum_{k=0}^\\infty \\frac{p(k)}{p^{sk}}\\). It can be shown that the products converge for \\(\\Re(s) &gt; 1\\), due to the asymptotics of partition numbers \\(p(k)\\) (which we will skip here).\nNow each inner sum is of the form \\(\\sum_{k=0}^\\infty \\frac{a(p^k)}{p^{sk}} = \\sum_{k=0}^\\infty \\frac{p(k)}{p^{sk}}\\). Let \\(x = \\frac{1}{p}\\). Then we have the sum \\(\\sum_{k=0}^\\infty p(k)x^{sk}\\).\nThis is the ordinary generating function for the partition function, which also can be written as \\(\\prod_{k=1}^\\infty \\frac{1}{1 - x^{sk}}\\). This is valid since \\(\\frac{1}{p} &lt; 1\\).\nThus we can rewrite \\(f(n) = \\prod_p \\prod_{k=1}^\\infty \\frac{1}{1 - (\\frac{1}{p})^{sk}}\\). Applying the Fubini-Tonelli theorem4 lets us rearrange the product to get \\(\\prod_p \\prod_{k=1}^\\infty \\frac{1}{1 - (\\frac{1}{p})^{sk}} = \\prod_{k=1}^\\infty \\prod_p \\frac{1}{1 - (\\frac{1}{p})^{sk}} = \\prod_{k=1}^\\infty \\zeta(ks)\\).\n4 See here for a summary. In general, this will let us change the order of summation / multiplication.5 We omit the proof of this here, but roughly the terms \\(\\zeta(ks) \\rightarrow 1\\) as \\(k \\rightarrow \\infty\\), and in fact this convergence is geometric in nature. We can then show that if we ignore the first few terms, in the strip \\(\\frac{1}{n+1} &lt; \\Re(s) &lt; \\frac{1}{n}\\), the product converges, and will gives us a meromorphic continuation of the function.Thus the Dirichlet generating function for \\(a(n)\\) is \\(\\prod_{k=1}^\\infty \\zeta(ks)\\), which converges when \\(\\Re(s) &gt; 1\\). In fact we can meromorphically expand this to \\(\\Re(s) &gt; 0\\), by noting that there are poles at \\(1, \\frac{1}{2}, \\frac{1}{3} \\ldots \\frac{1}{n} \\ldots\\), but the product still converges outside of those areas. 5"
  },
  {
    "objectID": "posts/counting_abelian_groups/counting_abelian_groups.html#counting-the-number-of-abelian-groups",
    "href": "posts/counting_abelian_groups/counting_abelian_groups.html#counting-the-number-of-abelian-groups",
    "title": "Counting the number of abelian groups",
    "section": "Counting the number of abelian groups",
    "text": "Counting the number of abelian groups\nWe’ve buried the lede so far on how we are going to estimate \\(\\sum_{n\\le x} a(n)\\). In particular, Perron’s Formula says that if \\(f(s)\\) is the Dirichlet generating function for \\(a(n)\\), then we have that if \\(f(s)\\) is uniformly convergent for \\(\\Re(s) &gt; \\sigma\\) for some fixed \\(\\sigma\\), and \\(c &gt; \\sigma\\), then6\n6 For \\(x\\) an integer, we need to modify the sum so that the last term \\(a(x)\\) is multiplied by \\(\\frac{1}{2}\\). Otherwise the left-hand side is an ordinary sum.\\[\\sum_{n\\le x} a(n) + O(\\sum_{n=1}^\\infty(\\frac{x}{n})^c \\frac{a(n)}{T|\\log \\frac{x}{n}|}) = \\frac{1}{2\\pi i} \\int_{c-iT}^{c+iT} f(s)\\frac{x^s}{s}ds\\]\nThat is, if we we compute the line integral of the function \\(A(s) = f(s)\\frac{x^s}{s}\\) over the truncated line \\(\\Re(s) = c\\), that should give us what we want plus an error term. Figure 2 shows the contour for \\(\\Re(s) = 2\\).\n\n\n\n\n\n\n\n\n\nFigure 2: Contour for Perron’s Formula\n\n\n\n\nLet’s bound the error term.\nWhen \\(n &lt; 0.9x\\) or \\(n &gt; 1.1x\\) we have that\n\\(O(\\sum (\\frac{x}{n})^c \\frac{a(n)}{T|\\log \\frac{x}{n}|}) = O(\\frac{x^c}{T}\\sum \\frac{a(n)}{n^c}) = O(\\frac{x^c\\prod_{k=1}^\\infty \\zeta(kc)}{T}) = O(\\frac{x\\log x}{T})\\).\nThe latter equality is a combination of three steps. We first fix \\(c = 1 + \\frac{1}{\\log x}\\) which gives us the linear power in \\(x\\). Also, noting that \\(\\prod_{k=2}^\\infty \\zeta(kc)\\) is bounded, we only need to consider the \\(\\zeta(c)\\) term. As \\(\\zeta(c) = O(\\frac{1}{|c - 1|})\\), for \\(c\\) approaching 1, the rest follows.\nFor \\(0.9x \\le n \\le 1.1x\\), \\(O(\\sum_{0.9x \\le n \\le 1.1x} (\\frac{x}{n})^c \\frac{a(n)}{T|\\log \\frac{x}{n}|}) = O(\\sum_{0.9x \\le n \\le 1.1x} \\frac{a(n)}{T|\\log \\frac{x}{n}|})\\).\nWe’ll assume now that \\(x = \\lfloor x \\rfloor + \\frac{1}{2}\\). That is, \\(x\\) is a half integer. Then, \\(\\frac{1}{|\\log \\frac{x}{n}|} = O(|\\frac{x}{n - x - \\frac{1}{2}}|)\\), since \\(n\\) is close to \\(x\\).\nIf \\(k = n - x\\), we have our error bounded by \\(O(\\frac{x}{T}\\sum_{|k| \\le 0.1 x} \\frac{1}{|k - \\frac{1}{2}|}) = O(\\frac{x\\log x}{T})\\) 7\n7 The latter inequality comes from the fact that the Harmonic numbers grow like \\(\\log x\\).\nModified Integral\nWe’ll modify the main integral by relating it to a shifted integral on the left hand size of the pole at 1.\nLet \\(c = 1 + \\frac{1}{\\log x}, \\frac{1}{2} &lt; \\delta &lt; 1\\). Let \\(A = \\prod_{k=2}^\\infty \\zeta(k)\\), and consider the contour in Figure 3, where we are integrating over it in the counterclockwise direction.\n\n\n\n\n\n\n\n\n\nFigure 3: Modified Contour\n\n\n\n\nThis contour \\(B\\) is now a box around the pole \\(1\\). \\(C_1\\) corresponds to our original contour (of length \\(2T\\)) while \\(C_3\\), is a shifted version.\nWe have the sides of the box parameterized as:\n\\(C_1 = \\{s | \\Re(s) = c, -T \\le \\Im(s) \\le T\\}\\)\n\\(C_2 = \\{s | \\Im(s) = -T, \\delta \\le \\Re(s) \\le c\\}\\)\n\\(C_3 = \\{s | \\Re(s) = \\delta, -T \\le \\Im(s) \\le T\\}\\)\n\\(C_4 = \\{s | \\Im(s) = T, \\delta \\le \\Re(s) \\le c\\}\\)\nSince \\(\\delta &gt; \\frac{1}{2}\\), the box does not have any poles on its path, and only contains one pole inside. We have by the residue theorem, the value of this new contour is \\(\\frac{1}{2\\pi i}\\int_B f(s)\\frac{x^s}{s} ds = Res_{s=1} f(s)\\frac{x^s}{s} = \\prod_{k=2}^\\infty \\zeta(k) x = Ax\\)\nThus, breaking apart \\(B\\) into its constituent integrals, we get that \\(Ax = \\sum_{n\\le x}a(n) + O(\\frac{x\\log x}{T}) + \\int_{C_2 \\cup C_3 \\cup C_4} f(s)\\frac{x^s}{s} ds\\).\nWe will now bound the contours \\(C_2, C_3, C_4\\).\nFor \\(C_2\\), we can bound \\(|f(s)|\\) by \\(B|\\zeta(s)|\\) where \\(B = \\prod_{k=2}^\\infty \\zeta(k\\delta)\\). This is due to the monotonicity of \\(\\zeta(s)\\) for \\(s &gt; 1\\), and that since \\(\\delta &gt; \\frac{1}{2}\\), \\(k\\delta &gt; 1, \\, \\forall k \\ge 2\\).\nIt is also known that \\(|\\zeta(s)| = O((1 + |\\Im(s)|)^{1 - \\Re(s)}\\log(1 + \\Im(s))\\), for \\(\\Im(s) &gt; 2, \\Re(s) &gt; 0\\).\nThus, for \\(C_2\\) we have the bound \\(|\\int_{C_2} f(s)\\frac{x^s}{s} ds| = O(\\int_\\delta^c |\\zeta(s + iT)||\\frac{x^{s + iT}}{s + iT}| ds) = O(\\int_\\delta^c \\frac{x^s(1 + T)^{1 - s} \\log T}{T}  ds) = O(\\frac{x\\log x}{T} + \\frac{x^\\delta T^{1-\\delta}\\log T}{T})\\) This same bound holds for \\(C_4\\) by a similar argument.\nFor \\(C_3\\) we have \\(|\\int_{C_3} f(s)\\frac{x^s}{s} ds| = O(\\int_{-T}^T|\\zeta(\\delta + iT)\\frac{x^{\\delta}}{\\delta + it}| dt) = O(\\int_{-T}^T(1 + |t|)^{1 - \\delta}\\frac{x^\\delta}{1 + |t|}\\log T dt) = O(x^\\delta T^{1 - \\delta}\\log T)\\)\nThus we have \\(Ax = \\sum_{n \\le x} a(n) + O(\\frac{x\\log x}{T}) + O(\\frac{x\\log x}{T} + \\frac{x^\\delta T^{1-\\delta}\\log T}{T}) + O(x^\\delta T^{1 - \\delta}\\log T)\\)\nLet \\(\\delta = \\frac{1}{2} + \\epsilon\\), for \\(\\epsilon &gt; 0\\). Let \\(T = \\sqrt{x}\\). Then we have the errors are of the form\n\\(O(\\sqrt{x}\\log x) + O(\\sqrt{x} \\log x + x^{\\frac{1}{4} - \\epsilon}\\log x) + O(x^{\\frac{1}{2} + \\epsilon} x^{\\frac{1}{4} - \\frac{\\epsilon}{2}}\\log x) = O(x^{\\frac{3}{4} + \\epsilon})\\).\nThe error is sublinear, and we are done.\nMore careful treatment can reduce this error down to \\(O(\\sqrt{x})\\). In fact8 we have\n8 See here for a summmary of asymptotics for this problem.\\[\\sum_{n\\le x} a(n) \\sim Ax + B\\sqrt{x} + Cx^{\\frac{1}{3}} + O(x^{\\frac{3}{10}}(\\log x)^{\\frac{9}{10}})\\]\n\\(A = \\prod_{k=1, k \\ne 1}^\\infty \\zeta(k)\\)\n\\(B = \\prod_{k=1, k \\ne 2}^\\infty \\zeta(\\frac{k}{2})\\)\n\\(C = \\prod_{k=1, k \\ne 3}^\\infty \\zeta(\\frac{k}{3})\\)\nOne can see that the constants \\(B\\) and \\(C\\) come from evaluating the residue of our integrand at the pole at \\(\\frac{1}{2}\\) and at \\(\\frac{1}{3}\\). The arguments get harder here with our tools because we will start accumulating more factors of \\(\\zeta(s)\\) in the critical strip, which means we need tighter control of the growth rate of \\(\\zeta(s)\\) in the strip."
  },
  {
    "objectID": "posts/trapezoid_mc/quad_mc.html",
    "href": "posts/trapezoid_mc/quad_mc.html",
    "title": "Trapezoid Rule Monte Carlo",
    "section": "",
    "text": "I recently encountered a Monte Carlo estimator (Masry and Cambanis 1990) that uses the trapezoid rule and wanted to write out / generalize it.\nGiven a function \\(f\\) (we’ll assume \\(f\\) is \\(C^\\infty\\) for simplicity, but some of these arguments can be changed depending on the smoothness) defined on the unit interval \\([0, 1]\\), we would like to compute the integral \\(I = \\int_0^1 f(x) dx\\). Quadrature methods can easily deal with estimating these integrals 1\nOur plan will be to come up with a lower variance (but biased) estimator, and then generalize to computing integrals of the form \\(\\int_A f(x) p(x) dx\\), where \\(p(x)\\) is a probability density on some subset of \\(\\mathbb{R}\\). Finally, we’ll be able to get an estimator even if we only have access to a sampler and the unnormalized log density (e.g. in the case of MCMC).\nThe typical Monte-Carlo estimator for this type of integral is \\(S_n = \\frac{1}{n}\\sum_{i=1}^n f(u_i)\\), where \\(u_i \\sim U(0, 1)\\) are IID uniform samples. This is an unbiased estimator for \\(I\\) and has variance \\(var(S_n) = \\frac{var(f)}{n}\\), where \\(var(f)\\) is the variance of the random variable \\(f(U), U \\sim U(0, 1)\\). In particular the variance is inversely proportional to \\(n\\)."
  },
  {
    "objectID": "posts/trapezoid_mc/quad_mc.html#trapezoid-rule-estimator",
    "href": "posts/trapezoid_mc/quad_mc.html#trapezoid-rule-estimator",
    "title": "Trapezoid Rule Monte Carlo",
    "section": "Trapezoid Rule Estimator",
    "text": "Trapezoid Rule Estimator\nIf we look at error estimates of various quadrature rules, we see that the errors get better dependency than \\(O(\\frac{1}{\\sqrt n})\\) for estimating \\(I\\).\n\n\nWe can see from the table that we can get errors \\(S_n - I\\) that are at least \\(O(\\frac{1}{n^2})\\) for various Newton-Cotes formula. From wikipedia.\n\n\n\n\n\n\n\nName\nError Bound\n\n\n\n\nTrapezoid Rule\n\\(-\\frac{1}{12n^2}f''(\\xi)\\)\n\n\nSimpson’s \\(\\frac{1}{3}\\) rule Rule\n\\(-\\frac{1}{90n^4}f^{(4)}(\\xi)\\)\n\n\nBoole’s Rule\n\\(-\\frac{8}{945n^6}f^{(6)}(\\xi)\\)\n\n\n\nwhere \\(\\xi\\) lies in the interval of integration \\([a, b]\\).\nThe main idea is we can exploit the structure of the trapezoid rule (and in general Newton-Cotes rules) to get better scaling of the variance with respect to the number of samples \\(n\\).\nGiven \\(n\\) samples \\(u_i \\sim U(0, 1)\\), we can sort the samples to form the order statistics \\(v_i\\). We’ll also add the points \\(0\\) and \\(1\\) to get \\(n + 1\\) points (let \\(v_0 = 0\\) and \\(v_{n + 1} = 1\\)).\nWe can then consider the trapezoid rule estimator: \\(S'_n = \\sum_{i=0}^{n} \\frac{1}{2} (v_{i+1} - v_i)(f(v_{i+1}) + f(v_i))\\)\n\n\n\n\n\n\n\n\n\nFigure 1: Randomized Trapezoid Rule for \\(\\sin(\\frac{\\pi}{2} x)\\)\n\n\n\n\nThe intuition is that for sufficiently smooth \\(f\\), \\(S'_n\\) should be a good estimator of the integral \\(I\\) due to the use of the trapezoid rule. Note that \\(S'_n\\) may be biased, and indeed Figure 1 shows an example of this, where the trapezoid rule approximates the integral well, but will always be an underestimate due to the concavity of the integrand. The hope is that we may trade off some bias for a reduction in variance.\nAs mentioned above, we can note the following deficiencies of this method, compared to quadrature rules and monte carlo rules.\n\nThis can be a biased estimator.\nThis is for \\(U(0, 1)\\) random variables and in one dimension, for which there are better methods.\nIn the current formulation, you have to evaluate the endpoints \\(0\\) and \\(1\\). This can be problematic for integrands (such as certain \\(Beta(\\alpha, \\beta)\\) densities which go off to \\(\\infty\\) in the tails). We can actually get away with \\(n\\) points without evaluating the \\(0\\) and \\(1\\) points. Adding the points just simplifies the analysis and reduces the error by a constant."
  },
  {
    "objectID": "posts/trapezoid_mc/quad_mc.html#error-bound-on-s_n",
    "href": "posts/trapezoid_mc/quad_mc.html#error-bound-on-s_n",
    "title": "Trapezoid Rule Monte Carlo",
    "section": "Error bound on \\(S'_n\\)",
    "text": "Error bound on \\(S'_n\\)\nLet’s take a look at the error \\(S'_n - I\\).\nFor simplicity we’ll reuse a form of the Trapezoid Rule Error 2.\n2 See hereIf we are estimating \\(\\int_{v_i}^{v_{i+1}} f(x) dx\\), then the error of using \\(\\frac{1}{2}(f(v_{i+1}) + f(v_{i}))(v_{i+1} - v_i)\\) is bounded by \\(\\frac{K_i(v_{i+1} - v_i)^3}{12}\\), where \\(K_i = \\sup_{[v_i, v_{i+1}]} |f''(x)|\\) (this can be derived through repeated applications of the Mean Value Theorem).\n\\(|S'_n - I| = |-\\int_0^1 f(x) dx + \\sum_{i=0}^{n}\\frac{1}{2}(v_{i+1} - v_i) (f(v_{i+1}) - f(v_i))|\\)\n\\(=|\\sum_{i=0}^{n}\\frac{1}{2}(v_{i+1} - v_i) (f(v_{i+1}) + f(v_i)) - \\int_{v_i}^{v_{i+1}} f(x) dx|\\)\n\\(\\le\\sum_{i=0}^{n}|\\frac{1}{2}(v_{i+1} - v_i) (f(v_{i+1}) + f(v_i)) - \\int_{v_i}^{v_{i+1}} f(x) dx|\\)\n\\(\\le\\sum_{i=0}^{n}\\frac{K_i}{12}(v_{i + 1} - v_i)^3\\)\n\\(\\le\\frac{K}{12}\\sum_{i=0}^{n}(v_{i + 1} - v_i)^3\\)\nLet \\(x_i = v_{i+1} - v_i\\). It’s well known that these lengths are jointly distributed like a Dirichlet 3.\n3 See hereThis makes the \\((x_0, ... , x_{n}) \\sim Dirichlet(1, 1, ...., 1)\\)\nWe’ll use the following properties of moments of the Dirichlet distribution (n.d.).\n\nLin, Jiayu. n.d. “On the Dirichlet Distribution.” https://mast.queensu.ca/~communications/Papers/msc-jiayu-lin.pdf.\n\\(\\mathbb{E}[X_i^k] = \\frac{\\Gamma(n)}{\\Gamma(n + k)} \\frac{\\Gamma(k + 1)}{\\Gamma(1)} = \\frac{(n - 1)!k!}{(n + k - 1)!} = \\frac{k!}{n (n + 1) (n + 2) ... (n + k - 1)}\\) \\(\\mathbb{E}[X_i^kX_j^k] = \\frac{\\Gamma(n)}{\\Gamma(n + 2k)} \\frac{\\Gamma(k + 1)^2}{\\Gamma(1)} = \\frac{(n - 1)!(k!)^2}{(n + 2k - 1)!} = \\frac{k!^2}{n (n + 1) (n + 2) ... (n + 2k - 1)}\\)\nThat is the \\(k\\)-th marginal moment grows like \\(O(\\frac{1}{n^k})\\). and that the mixed moment \\(\\mathbb{E}[X_i^kX_j^k]\\) grows like \\(O(\\frac{1}{n^{2k}})\\).\nWe can look at \\(\\mathbb{E}[(S'_n - I)^2] = \\mathbb{E}[(\\frac{K}{12})^2 (\\sum_{i=0}^{n + 1}(x_i)^3)^2]\\) = \\(\\frac{K^2}{144}\\sum_{i, j} \\mathbb{E}[x_i^3x_j^3]\\)\nAs the sum over the \\((n + 2)^2\\) terms is over moments which are all \\(O(\\frac{1}{n^6})\\), this results in \\(\\mathbb{E}[(S'_n - I)^2)] = O(\\frac{1}{n^4})\\) (with an \\(O(\\frac{1}{n^2})\\) bound on the bias) 4. A precise bound can be derived by carrying through the constants from the Trapezoid Rule and the Dirichlet moments.\n4 One can easily get an error bound on the bias \\(|\\mathbb{E}[S'_n - I]|\\) without squaring the sum. Mainly looking at \\(\\mathbb{E}[(S'_n - I)^2]\\) gives us a stronger form of convergence, and one can still recover a bound on the bias."
  },
  {
    "objectID": "posts/trapezoid_mc/quad_mc.html#examples",
    "href": "posts/trapezoid_mc/quad_mc.html#examples",
    "title": "Trapezoid Rule Monte Carlo",
    "section": "Examples",
    "text": "Examples\nHere’s some example on a few different functions on \\([0, 1]\\)\n\n\\(f = \\frac{1}{1 + x^2}\\)\n\\(g = e^x\\sin(\\frac{x}{2})\\)\n\\(h = x^3 - x + x^2\\).\n\n\n\n\n\nTable 1: Absolute Error in estimating the integral of \\(f = \\frac{1}{1 + x^2}\\), \\(g = e^x \\sin(\\frac{x}{2})\\), \\(h = x^3 - x + x^2\\).\n\n\n\n\n\n\n\n\nIntegral\nMethod\nN=10\nN=50\nN=100\nN=200\nN=1000\n\n\n\n\n0.785398\nMonte Carlo\n0.026491\n0.019358\n0.008144\n0.002608\n0.001540\n\n\n0.785398\nTrapezoid Rule\n0.000393\n0.000010\n0.000038\n0.000009\n0.000000\n\n\n0.785398\nSimpson's 1/3 Rule\n0.000002\n0.000010\n0.000001\n0.000000\n0.000000\n\n\n\n\n\n\n\n\n\n\nIntegral\nMethod\nN=10\nN=50\nN=100\nN=200\nN=1000\n\n\n\n\n0.488364\nMonte Carlo\n0.146778\n0.003383\n0.026795\n0.034787\n0.009164\n\n\n0.488364\nTrapezoid Rule\n0.005188\n0.000636\n0.000118\n0.000022\n0.000001\n\n\n0.488364\nSimpson's 1/3 Rule\n0.000131\n0.000002\n0.000000\n0.000000\n0.000000\n\n\n\n\n\n\n\n\n\n\nIntegral\nMethod\nN=10\nN=50\nN=100\nN=200\nN=1000\n\n\n\n\n0.083333\nMonte Carlo\n0.178741\n0.057350\n0.007101\n0.011000\n0.000868\n\n\n0.083333\nTrapezoid Rule\n0.011265\n0.001467\n0.000173\n0.000051\n0.000002\n\n\n0.083333\nSimpson's 1/3 Rule\n0.004317\n0.000017\n0.000001\n0.000000\n0.000000\n\n\n\n\n\n\n\n\nWe can see that the error of the estimates from the Trapezoid Monte Carlo estimator seem to decrease very rapidly."
  },
  {
    "objectID": "posts/trapezoid_mc/quad_mc.html#improving-the-estimator",
    "href": "posts/trapezoid_mc/quad_mc.html#improving-the-estimator",
    "title": "Trapezoid Rule Monte Carlo",
    "section": "“Improving” the Estimator",
    "text": "“Improving” the Estimator\nThe above estimator can be extended to other Newton-Cotes-type estimators. A Newton-Cotes formula is an integration rule that estimates the integral via the integration of a polynomial interpolant on \\(k + 1\\) equally spaced points.\nFor instance, the trapezoid rule is just the integral of the linear polynomial between two equally spaced points.\nFor our purposes, we can take the interpolant and use it to derive an integration rule on non-qequally spaced points.\nA Simpson’s Rule-type estimator, for instance would be of order 2 and use the \\(3\\) points next to each other (as seen in Figure 2).\n\n\n\n\n\n\n\n\n\nFigure 2: Randomized Simpson Rule for \\(\\sin(2 \\pi x)\\)\n\n\n\n\nThe interpolating polynomial through the ordered points \\(a, b, c\\) would be \\(p(x) = f(a)\\frac{(c - x)(b - x)}{(c - a)(b - a)} + f(b)\\frac{(c - x)(a - x)}{(c - b)(a - c)} + f(c)\\frac{(a - x)(b - x)}{(a - c)(b - c)}\\).\nThen \\(\\int_a^c p(x) dx = -\\frac{(a - c)(f(b)(a - c)^2 + f(a)(c - b)(2(b - a) - (c - b)) + f(c)(b - a)(2(c - b) - (b - a)))}{6(b - a)(c - b)}\\)\nIf we call this result \\(g(a, b, c)\\), then we can form the estimator\n\\(S''_n = \\sum_{i=0}^{\\frac{n - 1}{2}} g(v_{2i}, v_{2i+1}, v_{2i+2})\\)\nError analysis for this can proceed in a similar way (though very messily), which should result in an estimator with \\(\\mathbb{E}[(S''_n - I)^2] = O(\\frac{1}{n^8})\\). Similary we should have a \\(O(\\frac{1}{n^4})\\) bound on the bias.\nIn general, we can set up estimators from larger interpolating polynomials, to get asymptotically faster converging estimators 56.\n5 Note that polynomial interpolation on equally spaced points can be very numerically unstable. These estimators defend against this by being on random points, but some care needs to be taken.6 Note that while the Dirichlet moments will decay faster in \\(n\\) for higher order interpolants, they also pick up larger constants.As seen in Table 1, we empirically get faster convergence with the Simpson’s-rule type estimator."
  },
  {
    "objectID": "posts/trapezoid_mc/quad_mc.html#extending-to-other-probability-distributions",
    "href": "posts/trapezoid_mc/quad_mc.html#extending-to-other-probability-distributions",
    "title": "Trapezoid Rule Monte Carlo",
    "section": "Extending to other probability distributions",
    "text": "Extending to other probability distributions\nSuppose now we have \\(\\int_{[a, b]} f(x) p(x) dx\\), where \\(p(x)\\) is some probability density on some interval \\([a, b]\\)\nThe Monte Carlo estimate would be \\(\\sum_{i=0}^{n-1} f(x_i)\\), where \\(x_i \\sim p(x)\\). We would like to use our trapezoid estimator here, where we now have samples from \\(p(x)\\) rather than uniform samples.\nWe can naively apply the estimator by computing order statistics of \\(x_i\\), called \\(z_i\\), appending \\(a\\) and \\(b\\) to the ends much like before.\nThis gives the estimator \\(S'_n = \\sum_{i=0}^n \\frac{1}{2}(z_{i+1} - z_i) (f(z_{i+1})p(z_{i+1}) - f(z_i)p(z_i))\\)\nLet \\(v_i = F(z_i)\\), where \\(F\\) is the CDF (we’ll assume this is completely differentiable). Then we have\n\\(S'_n = \\sum_{i=0}^n \\frac{1}{2}(z_{i+1} - z_i) (f(z_{i+1})p(z_{i+1}) - f(z_i)p(z_i)))\\)\n\\(= \\sum_{i=0}^n \\frac{1}{2}(F^{-1}(v_{i+1})- F^{-1}(v_i)) (f(F^{-1}(v_{i+1}))p(F^{-1}(v_{i+1})) - f(F^{-1}(v_i))p(F^{-1}(v_{i+1})))\\)\nVia an application of the Mean Value Theorem we have: \\(S'_n = \\sum_{i=0}^n \\frac{1}{2}F'^{-1}(s_i) (v_{i+1} - v_i)(f(F^{-1}(v_{i+1}))p(F^{-1}(v_{i+1})) - f(F^{-1}(v_i))p(F^{-1}(v_i)))\\)\nfor some \\(s_i \\in [v_i, v_{i+1}]\\)\nThis suggests that if \\(\\sup_{[0, 1]} |F'^{-1}(u)|  = \\sup_{[a, b]} \\frac{1}{p(x)} &lt; \\infty\\), then we can pick up another constant and proceed with our error analysis as before, and thus get a \\(O(\\frac{1}{n^4})\\) bound on \\(\\mathbb{E}[(I - S'_n)^2]\\). More careful treatment in something like Phillipe (1997) can loosen this restriction.\nWe can apply this rule to a Beta density \\(p(x)\\) of a \\(Beta(2, 3)\\) random variable, with our functions from Table 1 to estimate \\(\\int_0^1 f(x)p(x) dx\\).\n\n\n\n\nTable 2: Absolute Error in estimating the integral of \\(f = \\frac{1}{1 + x^2}\\), \\(g = e^x \\sin(\\frac{x}{2})\\), \\(h = x^3 - x + x^2\\) with respect to the Beta distribution.\n\n\n\n\n\n\n\n\nIntegral\nMethod\nN=10\nN=50\nN=100\nN=200\nN=1000\n\n\n\n\n0.849556\nMonte Carlo\n0.022431\n0.015612\n0.006972\n0.006267\n0.003704\n\n\n0.849556\nTrapezoid Rule\n0.071244\n0.004386\n0.001175\n0.003429\n0.000172\n\n\n0.849556\nSimpson's 1/3 Rule\n0.021684\n0.000002\n0.000070\n0.000004\n0.000000\n\n\n\n\n\n\n\n\n\n\nIntegral\nMethod\nN=10\nN=50\nN=100\nN=200\nN=1000\n\n\n\n\n0.331193\nMonte Carlo\n0.047922\n0.032177\n0.012697\n0.005025\n0.003999\n\n\n0.331193\nTrapezoid Rule\n0.000814\n0.001131\n0.005256\n0.001520\n0.000146\n\n\n0.331193\nSimpson's 1/3 Rule\n0.011204\n0.000972\n0.001880\n0.001769\n0.000013\n\n\n\n\n\n\n\n\n\n\nIntegral\nMethod\nN=10\nN=50\nN=100\nN=200\nN=1000\n\n\n\n\n-0.085714\nMonte Carlo\n0.061996\n0.014922\n0.000664\n0.006580\n0.001264\n\n\n-0.085714\nTrapezoid Rule\n0.009933\n0.001845\n0.000278\n0.000761\n0.000123\n\n\n-0.085714\nSimpson's 1/3 Rule\n0.015353\n0.000206\n0.001751\n0.001618\n0.000059\n\n\n\n\n\n\n\n\nAs seen in Table 2, we can still outperform the naive Monte-Carlo estimator.\nIf we only have access to an unnormalized density \\(h(x)\\), \\(\\frac{h(x)}{Z} = p(x)\\), an application of Slutsky’s Theorem gives us the following estimator (where we simultaneously estimate the normalizing constant \\(Z\\)):\n\\(S'_n = \\frac{\\sum_{i=0}^n \\frac{1}{2}(z_{i+1} - z_i) (f(z_{i+1})h(z_{i+1}) - f(z_i)h(z_i))}{\\sum_{i=0}^n \\frac{1}{2}(z_{i+1} - z_i) (h(z_{i+1}) - h(z_i))}\\)\nThus, given a non-zero unnormalized density on \\([a, b]\\) and access to a sampler, we can estimate an expectation to any smooth function with this estimator 7.\n7 In general we can mix and match estimators for the normalizing constant in the denominator. These estimators will be consistent, but in general will not be unbiased."
  },
  {
    "objectID": "posts/trapezoid_mc/quad_mc.html#other",
    "href": "posts/trapezoid_mc/quad_mc.html#other",
    "title": "Trapezoid Rule Monte Carlo",
    "section": "Other",
    "text": "Other\nThis type of estimator seems to have been originally derived from Yakowitz and Szidarovszky (1978) for the unit interval. Phillipe (1997) and related works extend the Riemann sum estimator to other distributions.\n\n\n\nYakowitz, Krimmel, S., and F. Szidarovszky. 1978. “Weighted Monte Carlo Integration.” SIAM Journal on Numerical Analysis 15 (6): 1289–1300.\n\nPhillipe, Anne. 1997. “Importance Sampling and Riemann Sums.” Publications IRMA Université de Lille 43 (IV)."
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "Blog",
    "section": "",
    "text": "Counting the number of finite rings\n\n\n\nring-theory\n\nzeta-function\n\nasymptotics\n\n\n\nSeveral different counting formulas for different kind of rings including semisimple rings\n\n\n\nSrinivas Vasudevan\n\n\nOct 12, 2025\n\n\n\n\n\n\n\n\n\n\n\nCounting the number of abelian groups\n\n\n\ngroup-theory\n\nzeta-function\n\nasymptotics\n\n\n\nAn asymptotic formula for the number of abelian groups\n\n\n\nSrinivas Vasudevan\n\n\nOct 7, 2025\n\n\n\n\n\n\n\n\n\n\n\nGames As Graphs I: Bridges of Shangri-La\n\n\n\nboard-game\n\ngraph-theory\n\n\n\nUnderstanding Board Game Design via Graph Representations\n\n\n\nSrinivas Vasudevan\n\n\nSep 22, 2025\n\n\n\n\n\n\n\n\n\n\n\nTrapezoid Rule Monte Carlo\n\n\n\nmonte-carlo\n\nquadrature\n\n\n\nMixing the Trapezoid Rule with Monte Carlo\n\n\n\nSrinivas Vasudevan\n\n\nSep 19, 2025\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Srinivas Vasudevan",
    "section": "",
    "text": "Formerly at Google Research.\nBelow is my list of publications. See my Blog for recent writing or Board Games for boardgame design."
  },
  {
    "objectID": "index.html#section",
    "href": "index.html#section",
    "title": "Srinivas Vasudevan",
    "section": "",
    "text": "Formerly at Google Research.\nBelow is my list of publications. See my Blog for recent writing or Board Games for boardgame design."
  },
  {
    "objectID": "index.html#packages",
    "href": "index.html#packages",
    "title": "Srinivas Vasudevan",
    "section": "Packages",
    "text": "Packages\nI’ve worked on libraries in the general ML infrastructure, with a focus on probability and scientific computing\n Eigen,  JAX,  TensorFlow Probability,  TensorFlow"
  },
  {
    "objectID": "posts/games_as_graphs_i/games_as_graphs_i.html",
    "href": "posts/games_as_graphs_i/games_as_graphs_i.html",
    "title": "Games As Graphs I: Bridges of Shangri-La",
    "section": "",
    "text": "This is a series on understanding various boardgames via graph representations, with this post focusing on the Bridges of Shangri-La by Leo Colovini1.\nI’ve wanted to look at some games and write down mathematical descriptions for them. For me, this is a way to understand their design better, and also be a way to generate new ideas.\nSince this is the first of several posts, I’ll describe some fundamentals of Graph Theory."
  },
  {
    "objectID": "posts/games_as_graphs_i/games_as_graphs_i.html#graph-theory-primer",
    "href": "posts/games_as_graphs_i/games_as_graphs_i.html#graph-theory-primer",
    "title": "Games As Graphs I: Bridges of Shangri-La",
    "section": "Graph Theory Primer",
    "text": "Graph Theory Primer\nA graph \\(G\\) is a set of vertices \\(V\\) and a set of edges \\(E \\subset V \\times V\\). We can draw these graphs pretty easily Figure 1 .23\n2 To differentiate the undirected and directed graph, we’d have to distinguish between ordered and unordered tuples, but I’m being intentionally not rigorous since the meaning is clear with pictures.3 Note that a graph drawing is unique. We can move the edges and vertices around.\n\n\n\n\n\n\n\n\nFigure 1: Graphs on 4 vertices\n\n\n\n\nA graph where for all edges \\((u, v) \\in E, u \\ne v\\) is called a simple graph (edges with the same start and end points are called loops).\nGraphs can come in an undirected or directed flavor. In a directed graphs, the edges have an orientation (Figure 1).\nEdges and vertices may also have weights associated with them. These are typically used to assign costs. In general, different attributes can be assigned to an edge or vertex such as color (Figure 2).\n\n\n\n\n\n\n\n\n\nFigure 2: A more complicated graph on 10 vertices. Vertices are scaled by their edge weight \\(w\\) and are colored one of two colors.\n\n\n\n\nWhat does a graph represent? As much as limited by the imagination:\n\nThe vertices \\(V\\) could represent locations, and edges \\(E\\) represent whether two locations are reachable from each other. This includes maps, road networks, but even things like chess positions for something like a Knight’s Tour.\nThe vertices \\(V\\) are individuals, and the edges \\(E\\) represent contact. This could be used for something like a social network, but also disease modelling.\nFor a directed graph \\(G\\) The vertices \\(V\\) are tasks, and the edges \\(E\\) represent which task has to be done before the next. This includes things like supply chain management.\n\nAfter representing something as a graph, there are a variety of algorithms to deduce things about the graph. Some common problems include finding the shortest path, determining if there is a cycle, graph coloring, etc.\nWe won’t be needing these but may encounter these in future discussions."
  },
  {
    "objectID": "posts/games_as_graphs_i/games_as_graphs_i.html#bridges-of-shangri-la",
    "href": "posts/games_as_graphs_i/games_as_graphs_i.html#bridges-of-shangri-la",
    "title": "Games As Graphs I: Bridges of Shangri-La",
    "section": "Bridges of Shangri-La",
    "text": "Bridges of Shangri-La\nBridges of Shangri-La is a game by Leo Colovini for 3-4 players. It takes place on a map representing monasteries in Tibet.\nYour goal is to have the most number of masters out on the board after all the bridges have collapsed. Each master is worth 1 point.\nBefore I give a rough summary of the rules, I’ll depict the board as a map for simplicity of discussion 4.\n4 This is the 4P map. The top right corner is excluded for the 3P game.\n\n\n\n\n\n\n\nFigure 3: Bridges of Shangri-La map as a graph.\n\n\n\n\n\nEach vertex represents a village, and each edge represents a bridge. Each village also has 7 spots for the 7 different types of masters 5.\n5 \n\n\nExample of placing masters\n\n\nAt the very beginning of the game, each player will place one of each type of master (in their player color) into villages of their choice. That will be 7 placements for each player. Each spot is exclusive.\nOn a players’ turn they have one of three actions:\n\nPlace a master: You can only do this in a village where you have a master of your color and if there is an unoccupied space.\nRecruit students: You can place up to 2 students. You place a master tile on a master you already have, with the top tile called a student. Each master can only have one student.\nThe Journey of the Students: Choose two connected villages, and one of them being the one travelled from (“attacker”) and the other the (“defender”). The village that has the most tiles is considered stronger (with the village with the most masters and then “defender” breaking ties).\n\nIf the “attacker” is stronger, than all students in the “attacking” village move over to the “defender”, occupying their corresponding space (removing opponents tiles if they are occupied).\nIf the “defender” is stronger, than students only move over to empty spots, and otherwise get discarded.\nAfterwards, the bridge between the two villages gets destroyed.\n\n\nOnce all bridges are destroyed the game ends, with the player with the most masters on the board winning.\n\nGraph Representation\nAs seen in Figure 3, we can represent the game board as a graph. I’ll look at a simplified version of the game where there are only two types of masters (so that there are two slots in each village). For each type of master, we can have a copy of the graph as in Figure 4.\nTo show the placement of a master, color the node the player color and set the weight to 1. Increasing the weight of a vertex to 2 will represent showing that there is a student.\n\n\n\n\n\n\n\n\nFigure 4: In our simplified version we have two types of masters. Player placements of these masters is depicted by two separate graphs, one for each type of master.\n\n\n\n\n\nFor the actions have:\n\nPlace a master: Choose one of graph copies, and then choose a vertex with weight \\(0\\), such that the same vertex already has a master of the player’s color in a different graph. Then color it your player color and change it’s weight to 1 (as seen in Figure 5 (a))\nRecruit students: Choose two vertices that have your color and are weight \\(1\\) among the copies. Then increment their weight to \\(2\\) (as seen in Figure 5 (b))\nThe Journey of the Students: Essentially following the previous rules, with vertices of weight \\(2\\) interacting and representing the movement of the students. To get the strength of a village, sum the weights of the nodes in all copies of that vertex (the effect is seen in Figure 5 (c)).\n\n\n\n\n\n\n\n\n\n\n\n\n(a) Orange placing a master of the first type.\n\n\n\n\n\n\n\n\n\n\n\n(b) Blue adding a student to each of their masters.\n\n\n\n\n\n\n\n\n\n\n\n(c) Any player initiating a journey of students.\n\n\n\n\n\n\nFigure 5: Showing Bridges of Shangri-La actions in graph form."
  },
  {
    "objectID": "posts/games_as_graphs_i/games_as_graphs_i.html#game-analysis",
    "href": "posts/games_as_graphs_i/games_as_graphs_i.html#game-analysis",
    "title": "Games As Graphs I: Bridges of Shangri-La",
    "section": "Game Analysis",
    "text": "Game Analysis\nFirst for the map, we have each vertex has at most 4 edges. That is the degree of a vertex is atmost 4, and in fact \\(3 \\le deg(v) \\le 4,\\,  \\forall v \\in V\\).\n\nThe fact the number of edges varies a little bit breaks some symmetry, with the right / top-right of the board having smaller degree vertices, and so makes the initial placement a little more meaningful.\n\nNote also that when a spot is filled with a master, it will always be filled. This is because it either gains a master or gets displaced. This is also clear from looking at the weights of a vertex. If a vertex is positive, it will continue to be positive for the rest of the game.\n\nThis means that the game starts to narrow as there are fewer places to a master.\n\nFor almost all the discussion above, we haven’t needed graph theory, which begs the question why do any of this? For myself, I think it strips out ancillary (yet important details such as theme, etc.) details and gives a mathematical representation that can be manipulated. Viewing a game through the right lense could be suggestive of some design principals.\nFor instance, in the above representation I chose to have the game board be represented as multiple copies, with each copy representing a specific type of master / and it’s corresponding slots.\nThis is interesting because it is suggestive of a game design principle: create independent simple games, and then correlate them / make them interact through a few different actions to add complexity and shared incentives.\nIndeed, you can think of the 7 copies as separate games. The master placement rule requires some colocality of changing a vertex (you can only change a weight 0 vertex to weight 1, if it is at least weight 1 and your color in some copy). And the journey of the students requires evaluating the strength of a village. But after that, the student movements/placements can be treated independently.\nI think this does several different things:\n\nWith the game being similar to 7 independent subgames, some of the reasoning gets simplified (since different types of masters don’t directly interact).\nMaster placement colocality means predicting what an opponent can do is easier. This constraint is useful for making the game more strategic (and also intuitive rules-wise).\nEvaluating the strength of a village directly correlates different types of masters. This allows for shared incentives to emerge with different players.\n\nAnother thing is the game can be viewed very coarsely as a series of edge deletions. This then brings up questions for design, by looking at ablations of mathematical properties:\n\nHow does this game feel if some edges are directed?\nWhat if edge deletion was replaced by other graph operations? For example edge contraction combines two vertices (while removing the edge between them), and retains all the edges coming to/from those vertices. We can mix and match different graph operations and think about how that would influence game play.\nWhat if edges get deleted / removed for different types of masters? Specifically the journey of the students would delete an edge for some subset of the 7 copies of the graph (rather than all of them), so that certain students can still travel.\n\nOverall, by writing a mathematical representation we can get quite a few ideas on how to modify / get inspired to make games that retain some of the feeling of this one."
  },
  {
    "objectID": "posts/counting_rings/counting_rings.html",
    "href": "posts/counting_rings/counting_rings.html",
    "title": "Counting the number of finite rings",
    "section": "",
    "text": "Inspired by the attempt at counting abelian groups, we can attempt to look at counting other algebraic structures, this time for rings.\nOur recipe was:\n\nWrite down a multiplicative function for our counting problem.\nWrite down and simplify the Dirichlet generating function for said function.\nUse the tools of complex analysis to get asymptotics.\n\nIn general, our counting problems won’t follow some of the constraints here, and we’ll have to adapt accordingly.\nFor instance, it is nice if a function is multiplicative or completely multiplicative, but not necessary for the Dirichlet generating function. It just could make it easier to find a nice form for the function.\nFor 2), we need our counting function \\(f(n)\\) to grow at most polynomially in \\(n\\). Otherwise, our Dirichlet generating function will not converge anywhere in the complex plane, meaning we can’t use any of our tools. We will have to resort to other counting methods.\nWe will look at a few problems on asymptotics on counting rings \\(R\\), showing how we may have to use other tools for estimation. And then we will look at a problem that is very similar to our abelian group counting problem, using the same tools as before."
  },
  {
    "objectID": "posts/counting_rings/counting_rings.html#frac1xsum_n-le-x-fn",
    "href": "posts/counting_rings/counting_rings.html#frac1xsum_n-le-x-fn",
    "title": "Counting the number of finite rings",
    "section": "\\(\\frac{1}{x}\\sum_{n \\le x} f(n)\\)",
    "text": "\\(\\frac{1}{x}\\sum_{n \\le x} f(n)\\)\nLooking at \\(\\frac{1}{x}\\sum_{n \\le x} f(n)\\), we can investigate the size of the largest term. If \\(n = 2^{\\lfloor \\log_2 x \\rfloor}\\), then \\(f(n) = 2^{c(\\lfloor \\log_2 x \\rfloor)^3} \\le e^{c(\\log 2)^{-2}(\\log x)^3}\\). For \\(x\\) large enough this should be the largest term.\nThis is because if we look at \\(m^{c(\\lfloor \\log_m x \\rfloor)^3}\\), it can be shown that this is a decreasing function so will be maximized over primes at \\(m=2\\). We can then show that once we look at composite numbers, for \\(x\\) large enough, as well this function is maximized at a power of \\(2\\) (which is left for the reader).\nThis then gives a rough bound for \\(e^{c(\\lfloor \\log_2 x \\rfloor)^3 - \\log x} \\le \\frac{1}{x}\\sum_{n \\le x} f(n) \\le e^{c(\\log 2)^{-2}(\\log x)^3}\\), and thus we should have \\(e^{a(\\log x)^3} \\le \\frac{1}{x}\\sum_{n \\le x} f(n) \\le e^{b(\\log x)^3}\\), for some constants \\(a\\) and \\(b\\), showing the super-polynomial / sub-exponential growth."
  },
  {
    "objectID": "posts/counting_rings/counting_rings.html#frac1xsum_n-le-x-log-fn",
    "href": "posts/counting_rings/counting_rings.html#frac1xsum_n-le-x-log-fn",
    "title": "Counting the number of finite rings",
    "section": "\\(\\frac{1}{x}\\sum_{n \\le x} \\log f(n)\\)",
    "text": "\\(\\frac{1}{x}\\sum_{n \\le x} \\log f(n)\\)\n\n\n\n\n\n\n\n\n\n\n\n(a) Average of log number of rings of order N.\n\n\n\n\n\n\n\n\n\n\n\n(b) Average of log number of rings with identity of order N.\n\n\n\n\n\n\n\n\n\n\n\n\n\n(c) Average of log number of commutative rings of order N.\n\n\n\n\n\n\n\n\n\n\n\n(d) Average of log number of commutative rings with identity of order N.\n\n\n\n\n\n\n\nFigure 2: Average of \\(\\log r(n), \\log r^*(n), \\log c(n), \\log c^*(n)\\)\n\n\n\nWe can look at the average of \\(\\log f(n)\\). Because \\(f(n)\\) is so fast growing, most of the terms in the average do not matter, so looking at \\(\\log f(n)\\) might give some additional insight. This also means that \\(f(n)\\) acts like a polynomial so we could apply Dirichlet generating functions to this problem. We’ll do this implicitly, by invoking other results in analytic number theory. Figure 2 shows \\(\\frac{1}{x}\\sum_{n \\le x} \\log f(n)\\) computed for our ring counting functions.\nFor simplicity, let \\(c = 1\\) (this is a multiplicative constant that we can add in front later). In our case \\(\\log f(p^k) = k^3\\log p\\), and so \\(\\sum_{n \\le x} \\log f(n) = \\sum_{n \\le x} \\sum_{i=1}^m k_i^3 \\log p_i\\). We can rearrange the sum by grouping prime powers: \\(\\sum_{p^k \\le x} k^3 \\log p |\\{n \\le x |\\, p^k || n\\}|\\) The latter set’s cardinality is equal to \\(\\lfloor \\frac{x}{p^k} \\rfloor - \\lfloor \\frac{x}{p^{k+1}} \\rfloor\\), which is \\(x (\\frac{1}{p^k} - \\frac{1}{p^{k+1}}) + O(1)\\).\nThis lets us have \\(\\sum_{p^k \\le x} k^3 \\log p (x(\\frac{1}{p^k} - \\frac{1}{p^{k+1}}) + O(1)) = x\\sum_{p^k \\le x}k^3 \\log p \\frac{p - 1}{p^{k+1}} + O(\\sum_{p^k \\le x} k^3 \\log p)\\)\nIf we look at the latter sum inside the big-O, we can divide this into:\n\\(\\sum_{p \\le x} \\log p + 2^3\\sum_{p^2 \\le x} \\log p + 3^3 \\sum_{p^3 \\le x} \\log p \\ldots\\). The first term is the second chebyshev function \\(\\psi(x)\\). In fact we can write this series as\n\\(\\sum_{k=1}^{\\lfloor \\log_2 x \\rfloor} k^3 \\psi(x^{\\frac{1}{k}})\\). As we have \\(\\psi(x) \\sim x\\) by the Prime Number Theorem, this series is asympotically \\(x + O(\\sqrt{x}(\\log x)^4)\\).\nFor the first term we have \\(x\\sum_{p^k \\le x} k^3 \\log p \\frac{p-1}{p^{k+1}}\\).\nWe can bound the latter term by an infinite sum \\(\\sum_p \\sum_{k=1}^\\infty k^3 \\log p \\frac{p-1}{p^{k+1}} = \\sum_p \\frac{p-1}{p}\\log p\\sum_{k=1}^\\infty \\frac{k^4}{p^{k}}\\).\nOne can see that the inner sum is \\(O(\\frac{1}{p^2})\\), and so the total sum will be bounded for some constant \\(C\\) by \\(C\\sum_p \\frac{\\log p}{p^2}\\), which converges.\nThus we have \\(\\sum_{n \\le x}\\log f(n) = Mx + O(x) + O(\\sqrt{x}(\\log x)^4)\\), so \\(\\frac{1}{x}\\sum_{n\\le x}\\log f(n) = C + O(\\frac{(\\log x)^4}{\\sqrt{x}})\\), for some constant \\(C\\). In particular, for all our functions we have that \\(\\frac{1}{x}\\sum_{n \\le x} \\log f(n)\\) is bounded by some constant4\n4 This is the best we can do since each of these functions \\(\\log f(n)\\) has a \\(O(k^{2.5}\\log p)\\) term that we have ignored. As this term can vary, and does contribute linearly in a similar way to the cubic term, we could theoretically produce two constants \\(C_1\\) and \\(C_2\\), for which the average fluctuates between."
  }
]